

\section{Sequences, sequences and sequences}

Every Riordan array $\mathcal{R}$, as we've seen in 
\autoref{sec:back:to:the:basics:sequences}, has a particular sequence 
$\lbrace a_i\rbrace_{i\in\mathbb{N}}$,
called $A$-sequence, such that uniquely characterizes it (to be precise another sequence
$\lbrace z_i\rbrace_{i\in\mathbb{N}}$, called $Z$-sequence, is needed 
to fulfill the very first column, together with root element $d_{00}$), 
capturing the way every element $d_{n+1,k+1}$ can be written as a linear combination
of elements lying on the previous row, formally:
\begin{displaymath}
    d_{n+1,k+1} = a_{0}d_{n,k} +a_{1}d_{n,k+1} +a_{2}d_{n,k+2} + 
        \ldots + a_{j}d_{n,k+j}
\end{displaymath}
where $k+j = n$. In this section we would like to offer a generalization
of this \emph{combinatorial device}, providing a machinery to build sequences 
that combine coefficients, possibly lying on arbitrary rows, as desired.
Finally, a connection with $A$-matrix concept is explored, leaving an open 
question.

What follows doesn't use the $h$-characterization concept directly, 
we put it here because a \emph{column oriented}
approach, as used for derivation of $h$-characterizations, is used as well. 
For the sake of simplicity,
however, we start from an array $\mathcal{R}(d(t),h(t))$ and its 
$h$-characterization $\mathcal{R}_{h(t)}(g(h(t)), h(t))$, for some function $g$.

\subsection{Localizing $A$-sequences}

Consider the following question: there exists a sequence 
$\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ of coefficients 
such that the generic element $d_{n+1,k+1}\in\mathcal{R}$ can be written
as a linear combination of \emph{all} other elements $d_{n,j}$ 
lying on the previous row, namely for all $j\in\lbrace0,1,2,\ldots,n\rbrace$? 
Later we ask a more general question, for now tackle the current one.

The previous statement can be written in a compact way, or \emph{column-wise}, as:
\begin{displaymath}
    g(h(t))h(t)^k = \sum_{i\geq0}{\gamma_i\,t\,g(h(t)) h(t)^i}\\
\end{displaymath}
To see why, recall a generic column 
$k$ has generating function $g(h(t))h(t)^k$ and imagine that series written vertically, 
with increasing degree of $t$ from top to bottom.
The required constraint on coefficient of $t^n$, namely $d_{nk}$, 
to be a linear combination of elements lying on the previous row 
can be satisfied if we \emph{shift downward} every column,
namely multiplying each one by $t$, and combining them using coefficients
$\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$. 
We learned this trick from Shapiro introductory article \emph{The Riordan group}.

Simplification of $g(h(t))$ shows that using the factored representation or
the natural one doesn't make any difference, therefore:
\begin{displaymath}
    h(t)^k = t \sum_{i\geq 0}{\gamma_i\,h(t)^i} = t \Gamma(h(t))
\end{displaymath}
where function $\Gamma$ is a \ac{fps} over sequence 
$\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$, which we're searching for.
Doing a change of variable to abstract over $h(t)$, its possible to
\marginpar{$\hat{h}(y)^{\alpha}$ acts as a ruler which,
    if an element $d_{nk}$ is combined,
    scrolls to row $n-\alpha$}
structure the basic for a generic schema (or \emph{device} if you please):
\begin{displaymath}
    \left.\left[y^{k} = \hat{h}(y)\,\Gamma(y) \right| y = h(t) \right]
\end{displaymath}

Before going on, let the device consumes some known arrays. Take 
array $\mathcal{C}$, so $\hat{h}_{\mathcal{C}}(y) = y-y^2$, hence:
\begin{displaymath}
    \left.\left[\frac{y^{k-1}}{1-y} =  \Gamma(y) \right| y = h(t) \right]\\
\end{displaymath}
so sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ satisfies:
\begin{displaymath}
    \lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}} = 
        \left(\underbrace{\gamma_{0}=0,\ldots,\gamma_{k-2}=0}_{k-1 \text{ zeros}},
            \underbrace{\gamma_{k-1}=1, \ldots}_{\text{infinitely many ones}} \right)
\end{displaymath}
so $d_{nk}\in\mathcal{C}$ is the combination of \emph{all} coefficients
lying on previous row $n-1$ according $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$,
therefore $d_{nk}=\sum_{i=k-1}^{n-1}{d_{n-1,i}}$.
\marginpar{exactly as $A_{\mathcal{C}}(t)=\frac{1}{1-t}$ requires} 

Motzkin's turn, 
$\hat{h}_{\mathcal{M}}(y) = \frac{y}{1+y+y^2}$, hence:
\begin{displaymath}
        \left.\left[y^{k-1}+y^{k}+y^{k+1}=\Gamma(y)\right| y = h(t) \right]
\end{displaymath}
so sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ satisfies:
\begin{displaymath}
    \lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}} = 
        \left(\underbrace{\gamma_{0}=0,\ldots,\gamma_{k-2}=0}_{k-1 \text{ zeros}},
            1,1,1,
            \underbrace{\gamma_{k+2}=0, \ldots}_{\text{infinitely many zeros}} \right)
\end{displaymath}
\marginpar{exactly as $A_{\mathcal{M}}(t)=1+t+t^{2}$ requires} 
so $d_{nk}\in\mathcal{M}$ is the combination of \emph{all} coefficients
lying on previous row $n-1$ according $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$,
therefore $d_{nk}=d_{n-1,k-1}+d_{n-1,k}+d_{n-1,k+1}$.
\\\\
\marginpar{getting $A$-sequence back}
What we've done is nothing more nothing less than writing $A$-sequences 
in a more generic format, putting evidence on the \emph{local} meaning 
of the combination: it is explicitly written the dependency of 
elements belonging to a column $k$. On the other hand, natural $A$-sequences 
are stated with a fixed start index in mind, namely $k-1$ if combining 
for elements in a column $k$.

\marginpar{$y^{\beta}$ acts as a second ruler too, which scrolls
    to column $\beta$ directly. Rulers $y^{k-1}$ and $\hat{h}(y)$ 
    scroll to column $k-1$ and to row $n-1$ respectively, after 
    combination starts as $\Gamma$ says\ldots}
It is possible to get the natural $A$-sequence back by requiring that 
combination of elements (denoted by coefficients of \ac{fps} $\Gamma$)  
lying on the previous row (denoted by $\hat{h}(y)$)
starts at index $k-1$ (denoted by $y^{k-1}$), formally:
\begin{displaymath}
    \left[y^{k} = y^{k-1}\,\hat{h}(y)\,\Gamma(y) \big| y = h(t) \right] = 
    \left[y = \hat{h}(y)\,\Gamma(y) \big| y = h(t) \right]
\end{displaymath}
since $h(t) = t\,A(h(t))$, then \ac{fps}
$\Gamma$ and $A$ are defined over the same sequence, the $A$-sequence, as desired.
\\\\
\marginpar{The following can be skipped on a first reading}
Here there are a couple of applications. 

What if we ask: find a sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ 
such that an element $d_{nk}\in\mathcal{C}$ combines elements lying on a
row $3$ lines above, starting from column index $2$, 
namely $d_{n-3,k}$ for all $k\in\lbrace 2,\ldots,n-3\rbrace$. 
Set the device:
\begin{displaymath}
    \left[y^{k} = y^{2}\,\hat{h}(y)^3\,\Gamma(y) \big| y = h(t) \right] =
        \left.\left[\frac{y^{k-5}}{(1-y)^3} = \Gamma(y) \right| y = h(t) \right]
\end{displaymath}

Checking what we've obtained, assume you want to find coefficient $d_{7,5}$, 
chosen at random, so expand function $\Gamma$ with $k=5$:
\begin{displaymath}
    \left.\left[\Gamma(y)=1 + 3y + 6y^2 + 10y^3 + 15y^4 + \mathcal{O}(y^5) 
        \big| y = h(t) \right]\right|_{k=5}
\end{displaymath}
therefore $d_{7,5}=d_{4,2} + 3\,d_{4,3} + 6\,d_{4,4}$, 
instantiating $27 = 9 + 3\cdot4 + 6\cdot1$, which holds.
Just another element, say $d_{9,7}$, so expand function $\Gamma$ with $k=7$:
\marginpar{varing $k$ shifts $\lbrace \gamma_{i}\rbrace_{i\in\mathbb{N}}$ only.
    In \autoref{par:generalized:A:sequence:Delannoy:example}
    we will get a new sequence for each $k$}
\begin{displaymath}
    \left.\left[\Gamma(y)=y^2 + 3y^3 + 6y^4 + 10y^5 +  \mathcal{O}(y^6) 
        \big| y = h(t) \right]\right|_{k=7}
\end{displaymath}
therefore $d_{9,7}=d_{6,4} + 3\,d_{6,5} + 6\,d_{6,6}$, 
instantiating $44 = 20 + 3\cdot6 + 6\cdot1$, which holds.
It's interesting to observe the following fact: while a natural $A$-sequence
says how to combine starting always from the previous column index; with
this generalization we got the same coefficients for combining as $A$-sequence
states, augmenting with the column index from where the combination should start.

The previous two checks shows exactly this aspect: for column index $k=5$
combination starts at column index $2$, while for column index $k=7$ combination
starts at column index $4$.
\\\\
One last application, before the interlude: 
find a sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ such that 
an element $d_{nk}\in\mathcal{M}$ combines \emph{all} elements lying on 
the next row, namely $d_{n+1,k}$ for all $k\in\lbrace0,\ldots,n+1\rbrace$.
The first step is always setting the device:
\begin{displaymath}
    \left[y^{k} = \hat{h}(y)^{-1}\,\Gamma(y) \big| y = h(t) \right]=
        \left[ \frac{y^{k + 1}}{y^2 + y + 1} = \Gamma(y) \big| y = h(t) \right]
\end{displaymath}
in order to find $d_{6,3}$, chosen at random, expand function $\Gamma$ with $k=3$:
\begin{displaymath}
    \left.\left[\Gamma(y)=y^4 -y^5 + y^7 -y^8 +y^{10} + \mathcal{O}(y^{11}) 
        \big| y = h(t) \right]\right|_{k=3}
\end{displaymath}
therefore $d_{6,3}=d_{7,4} - d_{7,5} + d_{7,7}$, instantiating $44 = 70 -27 +1$, 
which holds. Just another element, say $d_{8,1}$, so expand function 
$\Gamma$ with $k=1$:
\begin{displaymath}
    \left.\left[\Gamma(y)=y^2 -y^3 + y^5 -y^6 + y^8 -y^9 + y^{11} + 
        \mathcal{O}(y^{12}) \big| y = h(t) \right]\right|_{k=1}
\end{displaymath}

\marginpar{what about $d_{n0}\in\mathcal{M}$? 
    it should provide a combinatorial identity for the $n$th
    Motzkin number\ldots}
therefore $d_{8,1}=d_{9,2} - d_{9,3} + d_{9,5}- d_{9,6}+ d_{9,8}- d_{9,9}$, 
instantiating $512 = 1422 -1140 +369 -147 +9 -1$, which holds.
\\\\
As a final remark, under the insights of two solved exercises, is that a
sequence found using this approach, knows which elements to combine and which
ones to discard, we're required to supply the set of available elements only.


\subsection{Interlude: let's generalize}
\label{subsec:sequences:interluce:generalization}

Previous applications shows a pattern that can be pointed out looking at 
the generic device for a Riordan array $\mathcal{R}$ where 
function $h$ is its second component and function $\hat{h}$ 
is its compositional inverse:
\begin{displaymath}
    \left[y^{k} = \hat{h}(y) \Gamma(y) \big| y = h(t) \right]
\end{displaymath}
there's \emph{an equation} on the left hand side of the variable substitution block, 
where function $\Gamma$ is the unknown. In this format, 
a constraint is stated: let $d_{nk}\in\mathcal{R}$ be a generic element, 
then a \emph{localized} sequence 
$\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ respect column $k$ exists, which
combines all elements lying on the previous row $n-1$.

Since we're dealing with an equation, we can augment it as desired in order to
constrain over additional facts. For instance, consider the following question:
find a sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ such that 
an element $d_{nk}\in\mathcal{R}$ combines \emph{all} elements lying on 
\emph{some} row $n-\alpha$, with the additional property to add the combination of 
elements, defined by a \emph{given} sequence $\lbrace \theta_{i} \rbrace_{i\in\mathbb{N}}$, 
lying on \emph{some different} row $n-\beta$. Formally, $\alpha,\beta\in\mathbb{Z}$ 
and $\alpha \not=\beta$, we would like to express $d_{nk}$ as:
\begin{displaymath}
    d_{nk} = \sum_{i=0}^{n-\alpha}{\gamma_{i}\,d_{n-\alpha,i}} + 
        \sum_{i=0}^{n-\beta}{\theta_{i}\,d_{n-\beta,i}}
\end{displaymath}
so set the device as usual:
\begin{displaymath}
    \left[y^{k} = \hat{h}(y)^{\alpha} \Gamma(y) + \hat{h}(y)^{\beta} \Theta(y) \big| y = h(t) \right]
\end{displaymath}
Nonetheless its generality, its not the best one: to be truly general,
we should introduce two new parameters $c_\mu$ and $c_\nu$, which allow
to fix the column index from where the combinations denoted by functions
$\Gamma$ and $\Theta$ start, respectively. Here is the most general device:
\marginpar{most general device}
\begin{displaymath}
    \left[y^{k} = y^{c_\mu}\hat{h}(y)^{\alpha} \Gamma(y) + 
        y^{c_\nu}\hat{h}(y)^{\beta} \Theta(y) \big| y = h(t) \right]
\end{displaymath}
\\\\
\paragraph{An example about $\mathcal{D}$}{
    \label{par:generalized:A:sequence:Delannoy:example}
    \marginpar{an example about $\mathcal{D}$}
    Try to make the generalization at work:
    find a sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ such that 
    an element $d_{nk}\in\mathcal{D}$, in the Delannoy array, 
    combines \emph{all} elements lying on 
    the next row, namely $n+1$, in addition to the
    combination of elements lying two row above, namely $n-2$, 
    defined as their sum, simply. 

    In order to set the device, we need $\hat{h}_{\mathcal{D}}$:
    \begin{displaymath} 
        \hat{h}_{\mathcal{D}}(y) = \frac{\sqrt{1+6y+y^2}-y-1}{2}
    \end{displaymath} 
    and build function $\Theta$ from the additional requirement:
    \begin{displaymath} 
        \Theta(y) = \frac{1}{1-y}
    \end{displaymath} 
    now we're ready:
    \begin{lenghtydisplaymath}
    \begin{split}
        &\left.\left[y^{k} = \hat{h}_{\mathcal{D}}(y)^{-1} \Gamma(y) + 
            \hat{h}_{\mathcal{D}}(y)^{2}\frac{1}{1-y} \right| y = h(t) \right]\\
        &=\left.\left[\frac{y^{3} + {\left(y^{2} - 1\right)} y^{k} + 6 \, y^{2} - {\left({\left(y - 1\right)} y^{k} + y^{2} + 3 \, y + 1\right)} \sqrt{y^{2} + 6 \, y + 1} + 6 \, y + 1}{2 \, {\left(1-y\right)}}=\Gamma(y) \right| y = h(t) \right]\\
    \end{split}
    \end{lenghtydisplaymath}
    in order to find $d_{8,1}$, chosen at random, expand function $\Gamma$ with $k=1$:
    \begin{lenghtydisplaymath}
        \left.\left[\Gamma(y)=y^2 -3y^3 + 11y^4  -47y^5 + 211y^6 -987y^7 + 4747y^8 
            -23335y^9 + \mathcal{O}(y^{10}) \big| y = h(t) \right]\right|_{k=1}
    \end{lenghtydisplaymath}
    therefore $d_{8,1}=d_{9,2} -3\,d_{9,3} +11\,d_{9,4}-47\,d_{9,5} 
        +211\,d_{9,6} -987\,d_{9,7} +4747\,d_{9,8}-23335\,d_{9,9}+\epsilon$,
        where $\epsilon = d_{6,0}+d_{6,1}+d_{6,2}+d_{6,3}+d_{6,4}+d_{6,5}+d_{6,6} = 
                2(d_{6,0}+d_{6,1}+d_{6,2})+d_{6,3} = 2(1 + 11 + 41) + 63 = 169$: 
        instantiating $15 = 113 -3\cdot377 +11\cdot681 -47\cdot681 +211\cdot377
            -987\cdot113 +4747\cdot17 -23335 + \epsilon = -154 + 169$, which holds.

    It's interesting to observe that function $\Gamma$ above, an algebraic one,
    produces sequences that use different coefficients for different values of $k$,
    and we observe a curious pattern for increasing values of 
    $k\in\lbrace 0,\ldots,10 \rbrace$:
    \begin{lenghtydisplaymath}
        \begin{split}
            &\left.\left[\Gamma(y)=
            1 y + {(-2)} y^{2} + 5 y^{3} + {(-17)} y^{4} + 65 y^{5} + {(-273)} y^{6} + 1213 y^{7} + {(-5617)} y^{8} + \mathcal{O}\left(y^{9}\right)
                \big| y = h(t) \right]\right|_{k=0}\\
            &\left.\left[\Gamma(y)=
            1 y^{2} + {(-3)} y^{3} + 11 y^{4} + {(-47)} y^{5} + 211 y^{6} + {(-987)} y^{7} + 4747 y^{8} + \mathcal{O}\left(y^{9}\right)
                \big| y = h(t) \right]\right|_{k=1}\\
            &\left.\left[\Gamma(y)=
            3 y^{4} + {(-19)} y^{5} + 99 y^{6} + {(-503)} y^{7} + 2547 y^{8} + {(-12971)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=2}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 6 y^{4} + {(-27)} y^{5} + 127 y^{6} + {(-615)} y^{7} + 3031 y^{8} + {(-15171)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=3}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-24)} y^{5} + 119 y^{6} + {(-587)} y^{7} + 2919 y^{8} + {(-14687)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=4}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 122 y^{6} + {(-595)} y^{7} + 2947 y^{8} + {(-14799)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=5}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-592)} y^{7} + 2939 y^{8} + {(-14771)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=6}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-593)} y^{7} + 2942 y^{8} + {(-14779)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=7}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-593)} y^{7} + 2941 y^{8} + {(-14776)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=8}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-593)} y^{7} + 2941 y^{8} + {(-14777)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=9}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-593)} y^{7} + 2941 y^{8} + {(-14777)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=10}\\
        \end{split}
    \end{lenghtydisplaymath}

    Starting from index $k=3$, it seems that one more coefficient stabilizes
    in the expansion, one increment of $k$ at a time, pretty nice.
    To finish this section involving Delannoy triangle, we report its natural
    $A$-sequence, computed with $\left.\left[y^{k} = y^{k-1}
    \hat{h}_{\mathcal{D}}(y)\,\Gamma(y) \right| y = h(t) \right]$:

    \marginpar{$\mathcal{D}$'s $A$-sequence which, of course, doesn't
        depend on $k$: it's unique\ldots}
    \begin{lenghtydisplaymath}
        \left[\Gamma(y)=
        1 + 2 y -2\,y^{2} + 6 y^{3} -22\,y^{4} + 90 y^{5} -394\,y^{6} + 1806 y^{7}  + \mathcal{O}\left(y^{8}\right)
            \big| y = h(t) \right]\\
    \end{lenghtydisplaymath}
}

\subsection{$A$-matrix connection}

Is the previous device the most general one? Really is it? 
We lie. In this section we enhance the last version to 
find an interesting connection with 
the $A$-matrix concept of a Riordan array $\mathcal{R}$, 
introduced in \autoref{sec:back:to:the:basics:sequences}.
\\\\
Let $\lbrace\Omega_{i}\rbrace_{i\in\mathbb{N}}$ be a collection of formal
power series and assume we would like to \emph{not} localize them (a-l\`a natural 
$A$-sequence) in order to combine elements lying on the previous row, on the previous
but one and so on \ldots hence, respect an element $d_{nk}\in\mathcal{R}$,
set the following device:

\marginpar{since columns are infinite, so is this device}
\begin{displaymath}
    \left.\left[
            \begin{split}
                y^{k} &= y^{k-1}\hat{h}(y) \Omega_{0}(y) \\
                &+ y^{k-1}\hat{h}(y)^{2} \Omega_{1}(y) \\
                &+ y^{k-1}\hat{h}(y)^{3} \Omega_{2}(y) \\
                &+ \ldots\\ 
                &+ y^{k-1}\hat{h}(y)^{i+1} \Omega_{i}(y)\\
                &+ \ldots
            \end{split}
        \right| y = h(t) \right]
\end{displaymath}
a simplification rewrites:
\begin{displaymath}
    \left.\left[
        y = \hat{h}(y) \Omega_{0}(y) + 
        \hat{h}(y)^{2} \Omega_{1}(y) + \hat{h}(y)^{3} \Omega_{2}(y) +
        \ldots +
        \hat{h}(y)^{i+1} \Omega_{i}(y) + \ldots
        \right| y = h(t) \right]
\end{displaymath}
Here are our thoughts, each in a dedicated subsection.

\subsubsection{Increasing generality}
It can be seen as an additional generalization of device introduced in
\autoref{subsec:sequences:interluce:generalization},
where some new functions are thrown in: it allows to augment the
combination including sets of coefficients lying on more rows, 
each of them combined according a function $\Omega_{j}$. 

\marginpar{one equation in one unknown}
If the combination is augmented using a fixed number $r$ 
of functions $\Omega_{0},\ldots,\Omega_{r-1}$
and $r-1$ of them $\Omega_{i_{0}},\ldots,\Omega_{i_{r-2}}$
are \emph{explicitly defined}, then it is possible to find 
the remaining one $\Omega_{i_{r-1}}$, because it is the same to solve a system
with one equation in one unknown.

% the following should be an attempt to find two rows in the
% `A-matrix' but it merely fails
%\subsubsection{Two characterizing functions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Assume we allow that combinations starts from column index $0$,
%%so the very general device in this case has the following form:
%\begin{displaymath}
    %\left.\left[
        %y^{k} = \hat{h}(y) \Omega_{0}(y) + \hat{h}(y)^{2} \Omega_{1}(y) 
            %\right| y = h(t) \right]
%\end{displaymath}
%Even if we don't define one of functions $\Omega_{0}$ or $\Omega_{1}$
%to find the other, it's possible to find \emph{both of them} by solving the system 
%obtained letting $k\in\lbrace0,1\rbrace$,
%formally functions $\Omega_{0}$ and $\Omega_{1}$ satisfy both:
%\begin{displaymath}
    %\left.\left[
        %1 = \hat{h}(y) \Omega_{0}(y) + \hat{h}(y)^{2} \Omega_{1}(y) 
            %\right| y = h(t) \right]
%\end{displaymath}
%and:
%\begin{displaymath}
    %\left.\left[
        %y = \hat{h}(y) \Omega_{0}(y) + \hat{h}(y)^{2} \Omega_{1}(y) 
            %\right| y = h(t) \right]
%\end{displaymath}

\subsubsection{$A$-sequence $\hat{h}$-representation}

It provides a ``representation'' of \ac{fps} $A$, over a corresponding
$A$-sequence $\lbrace a_{i}\rbrace_{i\in\mathbb{N}}$, ``in base'' $\hat{h}$, 
the compositional inverse of function $h$.  Recognizing $h(t)=tA(h(t))$ yield:
\begin{displaymath}
    \left.\left[
        A(y) =  \Omega_{0}(y) + 
        \hat{h}(y)\,\Omega_{1}(y) + \hat{h}(y)^{2}\,\Omega_{2}(y) + \ldots +
        \hat{h}(y)^{i}\,\Omega_{i}(y) + \ldots
        \right| y = h(t) \right]
\end{displaymath}

This is quite interesting from the theoretical point of 
view but it can also have a practical application
when functions $A$ and $\hat{h}$ are polynomials. If this is the case,
can apply the \emph{division theorem} among polynomial and 
proceed to factor polynomial $A$ dividing it by polynomial $\hat{h}$
repeatedly, until we got a $0$ remainder.

For the sake of clarity, consider the following cases:
\begin{itemize}

    % Pascal's $A$-sequence
    \item let $\mathcal{P}$ be the Pascal array $\mathcal{P}$ and recall 
        the following facts:
        
        \marginpar{apply it to $A_{\mathcal{P}}$}
        \begin{displaymath} 
            \hat{h}_{\mathcal{P}}(y)=\frac{y}{1+y} \quad\quad A_{\mathcal{P}}(y)=1+y
        \end{displaymath} 
        therefore, by \emph{division theorem}, 
        there exist polynomials $\Omega_{0}$ and $\Delta_{0}$ such that:
        \begin{displaymath}
            \left.\left[
                (1+y)^2 =  (1+y)\Omega_{0}(y) + y\,\Delta_{0}(y) \right| y = h_{\mathcal{P}}(t) \right]
        \end{displaymath}
        dividing $(1+y)^2$ by $y$ yield $\Delta_{0}(y)=2+y$ and $(1+y)\Omega_{0}(y)=1$, 
        which defines polynomial $\Omega_{0}$. We need to 
        keep applying \emph{division theorem}, so there exist the following
        sequences of polynomials such that:

        %\vskip+20pt plus.5fill
        \marginpar{$\triangleq$ is the \emph{unify} operator}
        \begin{lenghtydisplaymath}
            \begin{split} 
                & \left.\left[
                    \frac{\Delta_{0}(y)}{\hat{h}_{\mathcal{P}}(y)} = 
                        \left(y+3, 2\right)\triangleq
                        \left(\Delta_{1}(y), (1+y)\Omega_{1}(y) \right)
                     \right| y = h_{\mathcal{P}}(t) \right]\\
                & \left.\left[
                    \frac{\Delta_{1}(y)}{\hat{h}_{\mathcal{P}}(y)} = 
                        \left(y+4, 3\right)\triangleq
                        \left(\Delta_{2}(y), (1+y)\Omega_{2}(y) \right)
                     \right| y = h_{\mathcal{P}}(t) \right]\\
                & \left.\left[
                    \frac{\Delta_{2}(y)}{\hat{h}_{\mathcal{P}}(y)} = 
                        \left(y+5, 4\right)\triangleq
                        \left(\Delta_{3}(y), (1+y)\Omega_{3}(y) \right)
                     \right| y = h_{\mathcal{P}}(t) \right]\\
                & \left.\left[
                    \frac{\Delta_{3}(y)}{\hat{h}_{\mathcal{P}}(y)} = 
                        \left(y+6, 5 \right)\triangleq
                        \left(\Delta_{4}(y), (1+y)\Omega_{4}(y) \right)
                     \right| y = h_{\mathcal{P}}(t) \right]\\
                &\vdots
            \end{split} 
        \end{lenghtydisplaymath}
        A pattern seems to emerge and can be captured with the 
        following rule in order to define polynomial $\Omega_{i}$:
        \begin{displaymath} 
                \left.\left[
                    \Delta_{i-1}(y) \triangleq 
                        q_{i-1}(y)\,\hat{h}_{\mathcal{P}}(y) + r_{i-1}
                        \rightarrow (1+y)\,\Omega_{i}(y)=r_{i-1} 
                    \right| y = h_{\mathcal{P}}(t) \right]
        \end{displaymath} 
        where each polynomial $q_{j}$ satisfies $q_{j}(0)\not=0$ and
        each $r_{j}\in\mathbb{N}$ is a remainder, with boundary initial 
        condition $\Delta_{-1}(y)=0\,\hat{h}_{\mathcal{P}}(y)+1$. 
        Therefore it is possible to state
        a closed formula for polynomial $\Omega_{i}$: 
        \begin{displaymath} 
            \Omega_{i}(y)=\frac{1+i}{1+y}
        \end{displaymath} 

        Putting it all together, the factorization of polynomial 
        $A_{\mathcal{P}}$ respect polynomial $\hat{h}_{\mathcal{P}}$ is:
        \begin{displaymath}
                \left.\left[
                    A_{\mathcal{P}}(y) = \sum_{i \geq0}{\left(\frac{1+i}{1+y}\right)
                        \hat{h}_{\mathcal{P}}(y)^{i}} \right| y = h_{\mathcal{P}}(t) \right]
        \end{displaymath}

    % Catalan's $A$-sequence
    \item for Catalan array $\mathcal{C}$ things are quite interesting,
        first of all recall the following facts:

        \marginpar{apply it to $A_{\mathcal{C}}$}
        \begin{displaymath} 
            \hat{h}_{\mathcal{C}}(y)=y-y^2 \quad\quad 
                A_{\mathcal{C}}(y)=\frac{1}{1-y}
        \end{displaymath} 
        therefore, by \emph{division theorem}, 
        there exist polynomials $\Omega_{0}$ and $\Delta_{0}$ such that:
        \begin{displaymath}
            \left.\left[
                1 = (1-y)\Omega_{0}(y) + y(1-y)^{2}\,\Delta_{0}(y) 
                    \right| y = h_{\mathcal{C}}(t) \right]
        \end{displaymath}
        \marginpar{congecture: is Catalan array's $A$-matrix \emph{unique}? 
            Moreover: $\Omega_{k}=0$ for $k>0$?}
        dividing $1$ by $y(1-y)^2$ yield $\Delta_{0}(y)=0$ 
        and $(1-y)\Omega_{0}(y)=1$, this define polynomial $\Omega_{0}$. 
        This means that ``polynomial'' $A_{\mathcal{C}}$ is already
        the factorization of itself, which is the same to say that
        there exists a \emph{unique} $A$-matrix for $\mathcal{C}$, pretty curious;

        \item for Motzkin array $\mathcal{M}$ things are quite interesting,
            first of all recall the following facts:
            \marginpar{apply it to $A_{\mathcal{M}}$}
            \begin{displaymath} 
                \hat{h}_{\mathcal{M}}(y)=\frac{y}{1+y+y^2} \quad\quad 
                    A_{\mathcal{M}}(y)=1+y+y^2
            \end{displaymath} 
            therefore, by \emph{division theorem}, 
            there exist polynomials $\Omega_{0}$ and $\Delta_{0}$ such that:
            \begin{displaymath}
                \left.\left[
                    (1+y+y^2)^2 = (1+y+y^2)\Omega_{0}(y) + y\,\Delta_{0}(y) 
                        \right| y = h_{\mathcal{M}}(t) \right]
            \end{displaymath}
            dividing $(1+y+y^2)^2$ by $y$ yield $\Delta_{0}(y)=2+3y+2y^2+y^3$ 
            and $(1+y+y^2)\Omega_{0}(y)=1$, this define polynomial $\Omega_{0}$,
            which expanded as fps equals: 
            \begin{displaymath}
                \left.\left[
                    \Omega_{0}(y) = 1 -y +y^{3} -y^{4} + y^{6} 
                        -y^{7} + y^{9} -y^{10} 
                        + y^{12} + \mathcal{O}\left(y^{13}\right)
                        \right| y = h_{\mathcal{M}}(t) \right]
            \end{displaymath}
            We need to keep applying \emph{division theorem}, so there exist 
            the following sequences of polynomials such that:
            \begin{lenghtydisplaymath}
                \begin{split} 
                    & \left.\left[
                        \frac{\Delta_{0}(y)}{\hat{h}_{\mathcal{M}}(y)} = 
                            \left(y^4 + 3y^3 + 6y^2 + 7y + 5, 2\right)\triangleq
                            \left(\Delta_{1}(y), (1+y+y^2)\Omega_{1}(y) \right)
                         \right| y = h_{\mathcal{M}}(t) \right]\\
                    & \left.\left[
                        \frac{\Delta_{1}(y)}{\hat{h}_{\mathcal{M}}(y)} = 
                            \left(y^5 + 4y^4+10y^3+16y^2 + 18y + 12, 5\right)\triangleq
                            \left(\Delta_{2}(y), (1+y+y^2)\Omega_{2}(y) \right)
                         \right| y = h_{\mathcal{M}}(t) \right]\\
                    & \left.\left[
                        \frac{\Delta_{2}(y)}{\hat{h}_{\mathcal{M}}(y)} = 
                            \left(y^6 + 5y^5 + 15y^4 + 30y^3 + 44y^2+46y+30, 
                                12\right)\triangleq
                            \left(\Delta_{3}(y), (1+y+y^2)\Omega_{3}(y) \right)
                         \right| y = h_{\mathcal{M}}(t) \right]\\
                    & \left.\left[
                        \frac{\Delta_{3}(y)}{\hat{h}_{\mathcal{M}}(y)} = 
                            \left(y^7+6y^6+21y^5+50y^4+89y^3+120y^2+120y+76, 30
                                \right)\triangleq
                            \left(\Delta_{4}(y), (1+y+y^2)\Omega_{4}(y) \right)
                         \right| y = h_{\mathcal{M}}(t) \right]\\
                    &\vdots
                \end{split} 
            \end{lenghtydisplaymath}
            A pattern seems to emerge and can be captured with the 
            following rule in order to define polynomial $\Omega_{i}$:
            \begin{displaymath} 
                    \left.\left[
                        \Delta_{i-1}(y) \triangleq q_{i-1}(y)\,\hat{h}_{\mathcal{M}}(y)
                        + r_{i-1} \rightarrow (1+y+y^2)\,\Omega_{i}(y)=r_{i-1}
                         \right| y = h_{\mathcal{M}}(t) \right]
            \end{displaymath} 
            where each polynomial $q_{j}$ satisfies $q_{j}(0)\not=0$ and
            each $r_{j}\in\mathbb{N}$ is a remainder, with boundary initial 
            condition $\Delta_{-1}(y)=1$.

            \marginpar{something similar already occurs within $\mathcal{P}$}
            It is quite interesting that, as the case for array $\mathcal{P}$,
            the sequence $\lbrace r_{j} \rbrace_{j\in\mathbb{N}}$ of remainders
            is exactly the sequence of coefficients of the function defining
            the second column of array $\mathcal{M}$ shifted by \emph{one}
            position, namely function $d_{\mathcal{M}}$ times function 
            $h_{\mathcal{M}}$. 
            
            Putting it all together, the factorization of polynomial 
            $A_{\mathcal{M}}$ respect polynomial $\hat{h}_{\mathcal{M}}$ is:
            \begin{displaymath}
                    \left.\left[
                        A_{\mathcal{M}}(y) = \sum_{i \geq0}{
                            \left(\frac{[t^{1+i}]d_{\mathcal{M}}(t)h_{\mathcal{M}}(t)}
                                {1+y+y^2}\right)
                            \hat{h}_{\mathcal{M}}(y)^{i}} 
                            \right| y = h_{\mathcal{M}}(t) \right]
            \end{displaymath}

        \item if terms are not in a polynomial ring, we've difficulty to show a
        factorization: for example Delannoy array $\mathcal{D}$ is affected by this difficulty.

    \end{itemize}

\subsubsection{Remaining thoughts}

\begin{itemize}
        
    \item looking at the formulation under study, we observe that functions
        $\Omega_{0}, \Omega_{1}, \Omega_{2}, \ldots$ are exactly the same
        as those introduced by Merlini et al., therefore we've expressed
        the concept of $A$-matrix from a different point of view. A problem
        is still open: what if we would like to find all such functions? A reply
        to this question seems interesting but we've no idea how to satisfy it.
        The major difficulty can be spotted looking at the device as a system:
        there's \emph{one} equation in possibly $k$ unknowns, no
        idea about the shape of the remaining $k-1$ equations.

        Have a little check about Pascal array $\mathcal{P}$ again:
        let $d_{nk}\in\mathcal{P}$, from the point above we've, firstly,
        $\Omega_{0}(y)=\frac{1}{1+y}$, which says to sum elements
        \added{lying} on row $n-1$ using alternating sings
        \replaced{; then add the doubled sum of
        elements lying on row $n-2$ using alternating signs; 
        then add the tripled sum of elements lying on row $n-3$ 
        using alternating signs; and so on \ldots}
        { and, secondly, $\Omega_{1}(y)=2+y$, 
        which says to double the ``first'' element and sum to the ``second'' element
        on row $n-2$}, all respect column index $k$. 
        
        Element $d_{7,4}$, chosen at random, is the combination 
        \replaced{$(d_{6,3}-d_{6,4}+d_{6,5}-d_{6,6})+
            2(d_{5,3}-d_{5,4}+d_{5,5}) + 3(d_{4,3}-d_{4,4}) + 4d_{4,4}$, 
            instantiating $35 = (20-15+6-1)+2(10-5+1)+3(4-1)+4\cdot1$
            }{
        $d_{6,3}-d_{6,4}+d_{6,5}-d_{6,6}+2d_{5,3}+d_{5,4}$, instantiating
        $35 = 20-15+6-1+2\cdot10+5$
        } which holds.

        \deleted[remark=boring and tedious the combination for $d_{8,1}$]{
            Element $d_{8,1}$, chosen at random, is the combination
            $d_{7,0}-d_{7,1}+d_{7,2}-d_{7,3}+d_{7,4}-d_{7,5}+d_{7,6}-d_{7,7}
                +2d_{7,0}+d_{7,1}$, instantiating 
                $8 = 1-7+21-35+35-21+7-1+2\cdot1+6$ which holds.}
        

        \added{On the other hand, let $d_{6,2}\in\mathcal{M}$ be the
        combination $(d_{5,1}-d_{5,2}+d_{5,4}-d_{5,5})
            +2(d_{4,1}-d_{4,2}+d_{4,4})
            +5(d_{3,1}-d_{3,2})
            +12(d_{2,1} -d_{2,2})
            +30\,d_{1,1}$, instantiating: 
            $69=(30-25+5-1)
            +2(12-9+1)
            +5(5-3)
            +12(2 -1)
            +30\cdot1$, which holds.}


\end{itemize}


