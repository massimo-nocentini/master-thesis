% article example for classicthesis.sty
\documentclass[11pt,a4paper]{article} % KOMA-Script article scrartcl
\usepackage{lipsum}
\usepackage{url}
\usepackage[nochapters,eulermath,beramono]{classicthesis} % nochapters
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{changes}
\usepackage{marginnote}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{proof}[theorem]{Proof}

\newcommand{\vect}[1]{\boldsymbol{#1}}

% for tracking changes
\definechangesauthor[name={under review}, color=blue]{testing}
\definechangesauthor[name={blending edge}, color=orange]{sid}

% an environment for lenghty equations breaking right margin
% taken from here:
% http://tex.stackexchange.com/questions/156877/center-over-long-equations-between-both-margins
\newsavebox{\overlongequation}
\newenvironment{lenghtydisplaymath}
 {\begin{displaymath}\begin{lrbox}{\overlongequation}$\displaystyle}
  {$\end{lrbox}\makebox[0pt]{\usebox{\overlongequation}}\end{displaymath}}

\begin{document}
    \title{\rmfamily\normalfont\spacedallcaps{Colouring Riordan arrays}}
    \author{\spacedlowsmallcaps{Donatella Merlini} \\ \spacedlowsmallcaps{Massimo Nocentini}}
    \date{\today} 
    
    \maketitle
    
    \begin{abstract}
        This short document is a collection of some \emph{Riordan arrays}, coloured 
        according different partition schemes.
    \end{abstract}
       
    \tableofcontents

    \newpage

    \section{Another characterization}

    \subsection{Main idea}

    Consider a \emph{Riordan array} $\mathcal{R}$ defined over generating
    functions $d(t)$ and $h(t)$. By definition, coefficients lying on 
    column $k$ are the coefficients of the following generating function:
    \begin{displaymath}
        d(t)h(t)^k
    \end{displaymath}
    our idea is to characterize $\mathcal{R}$ doing a variable change, as the
    following manipulation shows:
    \begin{displaymath}
        d(t)h(t)^k = d(t)(1 + (h(t)-1))^k = \left[ d(\hat{h}(1+y))(1+y)^k \left| y = h(t)-1 \right. \right]
    \end{displaymath}
    where $\hat{h}$ is the compositional inverse function of $h$, the one that
    satisfies $\hat{h}(h(t)) = t$: in order to get $t$ back, apply $\hat{h}$ to
    both members of $y+1 = h(t)$.
    Inside the square brackets there's a shape of a Riordan array, therefore:
    \begin{displaymath}
        \begin{split}
            \mathcal{R}\left(d(t),h(t)\right) &= \left[ \mathcal{R}\left(d(\hat{h}(1+y)), 1+y\right) \left| y = h(t)-1 \right. \right]\\
            &= \mathcal{R}_{y=h(t)-1}\left( f(y), 1+y \right) =  \mathcal{R}_{h(t)}\left( g(h(t)), h(t) \right) 
        \end{split}
    \end{displaymath}
    $\mathcal{R}_{y=h(t)-1}$ is interesting since its first component $f(y)$ allow to 
    develop another array $\mathcal{R}_{h(t)}$ where it's first component
    is a function $g$ in the ``variable'' $h(t)$, eventually the moral is:
    \begin{verse}
        using $d$ composed with $\hat{h}$ makes it possible to have $\mathcal{R}_{h}$,
        a characterization of $\mathcal{R}$ that depends only on $h$
    \end{verse}

    \subsection{Applying it to known triangles}

    In the following sections we study some well known arrays under this point of view.

    \subsubsection{Pascal}
    Let $\mathcal{P}$ be the Riordan array for the Pascal triangle,
    defined as:
    \begin{displaymath} 
        \mathcal{P} = \left(\frac{1}{1-t}, \frac{t}{1-t}  \right)
    \end{displaymath} 
    computing the compositional inverse of $h$ yields:
    \begin{displaymath} 
        \hat{h}(y) = \frac{y}{1+y}
    \end{displaymath} 
    so $f(y)=d(\hat{h}(1+y))=2+y$ therefore:
    \begin{displaymath} 
        \mathcal{P}_{y=h(t)-1}\left( 2+y, 1+y \right)= \mathcal{P}_{h(t)}\left( 1+h(t), h(t) \right)
    \end{displaymath} 
    Now study the generating function which carries coefficients lying on column $k$
    of $\mathcal{P}_{h(t)}$:
    \begin{displaymath} 
        h(t)^k + h(t)^{k+1}
    \end{displaymath} 
    hence coefficients of column $k$ are computed by sum of $k$ and $k+1$ convolution 
    of function $h$ with itself, which recall the work of Rogers on \emph{renewal arrays}.

    \subsubsection{Fibonacci}
    Let $\mathcal{F}$ be the Riordan array for the Fibonacci triangle,
    defined as:
    \begin{displaymath} 
        \mathcal{F} = \left(\frac{1}{1-t-t^2}, \frac{1-\sqrt{1-4t}}{2}  \right)
    \end{displaymath} 
    computing the compositional inverse of $h$ yields:
    \begin{displaymath} 
        \hat{h}(y) = y - y^2
    \end{displaymath} 
    so $f(y)=d(\hat{h}(1+y))=\frac{1}{1+y-2y^3-y^4}$ therefore:
    \begin{displaymath} 
        \begin{split} 
            & \mathcal{F}_{y=h(t)-1}\left( \frac{1}{1+y-2y^3-y^4}, 1+y \right) = \mathcal{F}_{h(t)}\left( \frac{1}{1-h(t)+2h(t)^3-h(t)^4}, h(t) \right)\\
        \end{split} 
    \end{displaymath} 
    Now study the generating function which carries coefficients lying on column $k$
    of $\mathcal{F}_{h(t)}$:
    \begin{displaymath} 
        \frac{h(t)^k}{1-h(t)+2h(t)^3-h(t)^4}
    \end{displaymath} 

    \subsubsection{Catalan}
    Let $\mathcal{C}$ be the Riordan array for the Catalan triangle,
    defined as:
    \begin{displaymath} 
        \mathcal{C} = \left(\frac{1-\sqrt{1-4t}}{2t}, \frac{1-\sqrt{1-4t}}{2}  \right)
    \end{displaymath} 
    computing the compositional inverse of $h$ yields:
    \begin{displaymath} 
        \hat{h}(y) = y - y^2
    \end{displaymath} 
    so $f(y)=d(\hat{h}(1+y))=\frac{\sqrt{4 \, y^{2} + 4 \, y + 1} - 1}{2 \, {\left(y + 1\right)} y}$ therefore:
    \begin{displaymath} 
        \begin{split} 
            &\mathcal{C}_{y=h(t)-1}\left(\frac{\sqrt{4 \, y^{2} + 4 \, y + 1} - 1}{2 \, {\left(y + 1\right)} y}, 1+y \right) \\
            &= \mathcal{C}_{h(t)}\left(\frac{\sqrt{4 \, h\left(t\right)^{2} - 4 \, h\left(t\right) + 1} - 1}{2 \, {\left(h\left(t\right) - 1\right)} h\left(t\right)}, h(t) \right)\\
            &= \mathcal{C}_{h(t)}\left(\frac{\sqrt{(2 h\left(t\right) -  1)^2} - 1}{2 \, {\left(h\left(t\right) - 1\right)} h\left(t\right)}, h(t) \right)\\
        \end{split} 
    \end{displaymath} 
    By cases on $\sqrt{(2 h\left(t\right) -  1)^2}$:
    \begin{itemize}
        \item $\sqrt{(2 h\left(t\right) -  1)^2}=2 h\left(t\right) -  1$, hence:
            \begin{displaymath} 
                \mathcal{C}_{h(t)}\left(\frac{2(h\left(t\right) -  1)}{2 \, {\left(h\left(t\right) - 1\right)} h\left(t\right)}, h(t) \right)=
                \mathcal{C}_{h(t)}\left(\frac{1}{h\left(t\right)}, h(t) \right)
            \end{displaymath} 
            since $h(0)=0$ the previous result has no meaning, therefore discard this case;
        \item $\sqrt{(2 h\left(t\right) -  1)^2}=1 -2 h\left(t\right)$, hence:
            \begin{displaymath} 
                \mathcal{C}_{h(t)}\left(\frac{h\left(t\right)}{ {\left(1-h\left(t\right) \right)} h\left(t\right)}, h(t) \right)=
                \mathcal{C}_{h(t)}\left(\frac{1}{1-h\left(t\right)}, h(t) \right)
            \end{displaymath} 
            checking against $h(0)=0$ the previous result has meaning, therefore accept this case.
    \end{itemize}
    Now study the generating function which carries coefficients lying on column $k$
    of $\mathcal{C}_{h(t)}$:
    \begin{displaymath} 
        \frac{h(t)^{k}}{1-h\left(t\right)} 
    \end{displaymath} 


    \subsubsection{Motzkin classic version}

    Let $\mathcal{M}$ be the Riordan array for the Motzkin triangle, defined as:
    \begin{displaymath} 
        \mathcal{M} =\left( \frac{1-t-\sqrt{1-2t-3t^2}}{2t^2},
           \frac{1-t-\sqrt{1-2t-3t^2}}{2t}  \right)
    \end{displaymath} 
    computing the compositional inverse of $h$ yields:
    \begin{displaymath} 
        \hat{h}(y) = \frac{y}{1+y+y^2}
    \end{displaymath} 
    so $f(y)=d(\hat{h}(1+y))$ equals:
    \begin{lenghtydisplaymath} 
        \begin{split} 
            & -\frac{{\left(y^{2} \sqrt{\frac{{\left(y^{2} + 4 \, y + 4\right)} y^{2}}{{\left(y^{2} + 3 \, y + 3\right)}^{2}}} - y^{2} + 3 \, y \sqrt{\frac{{\left(y^{2} + 4 \, y + 4\right)} y^{2}}{{\left(y^{2} + 3 \, y + 3\right)}^{2}}} - 2 \, y + 3 \, \sqrt{\frac{{\left(y^{2} + 4 \, y + 4\right)} y^{2}}{{\left(y^{2} + 3 \, y + 3\right)}^{2}}} - 2\right)} {\left(y^{2} + 3 \, y + 3\right)}}{2 \, {\left(y + 1\right)}^{2}} \\
            & = -\frac{{ \left(\sqrt{\frac{{\left(y^{2} + 4 \, y + 4\right)} y^{2}}{{\left(y^{2} + 3 \, y + 3\right)}^{2}}} \left( y^{2}+3y+3 \right) -\left(y^{2}+2y+2\right)\right){\left(y^{2} + 3 \, y + 3\right)}}}{2 \, {\left(y + 1\right)}^{2}} \\
            & = -\frac{ \left(\sqrt{\left(y^{2} + 4 y + 4\right) y^{2}} -\left(y^{2}+2y+2\right)\right)\left(y^{2} + 3y + 3\right)}{2 {\left(y + 1\right)}^{2}} \\
            & = -\frac{ \left(\sqrt{\left(\left(y + 2\right) y\right)^{2}} -\left(y^{2}+2y+2\right)\right)\left(y^{2} + 3y + 3\right)}{2 {\left(y + 1\right)}^{2}} \\
        \end{split} 
    \end{lenghtydisplaymath} 
    therefore:
    \begin{lenghtydisplaymath} 
        \begin{split} 
            &\mathcal{M}_{y=h(t)-1}\left(
                -\frac{ \left(\sqrt{\left(\left(y + 2\right) y\right)^{2}} -\left(y^{2}+2y+2\right)\right)\left(y^{2} + 3y + 3\right)}{2 {\left(y + 1\right)}^{2}} , 1+y \right) \\
            &= \mathcal{M}_{h(t)}\left(
            -\frac{{\left(\sqrt{\frac{{\left(h(t)^{2} + 2 \, h(t) + 1\right)} {\left(h(t) - 1\right)}^{2}}{{\left(h(t)^{2} + h(t) + 1\right)}^{2}}}\left( h(t)^{2} + h(t) + 1\right) 
                - (h(t)^{2} + 1) \right)} {\left(h(t)^{2} + h(t) + 1\right)}}{2 \, h(t)^{2}} , h(t) \right)\\
            &= \mathcal{M}_{h(t)}\left(
            -\frac{{\left(\sqrt{\left(h(t)^2 - 1\right)^{2}} - (h(t)^{2} + 1) \right)} {\left(h(t)^{2} + h(t) + 1\right)}}{2 \, h(t)^{2}} , h(t) \right)\\
        \end{split} 
    \end{lenghtydisplaymath} 
    By cases on $\sqrt{\left(h(t)^2 - 1\right)^{2}}$:
    \begin{itemize}
        \item $\sqrt{\left(h(t)^2 - 1\right)^{2}}= h(t)^2 - 1$, hence:
            \begin{displaymath} 
                \mathcal{M}_{h(t)}\left(\frac{ h(t)^{2} + h(t) + 1}{h(t)^{2}} , h(t) \right)\\
            \end{displaymath} 
            since $h(0)=0$ the previous result has no meaning, therefore discard this case;
        \item $\sqrt{\left(h(t)^2 - 1\right)^{2}}= 1-h(t)^2$, hence:
            \begin{displaymath} 
                \mathcal{M}_{h(t)}\left( h(t)^{2} + h(t) + 1, h(t) \right)\\
            \end{displaymath} 
            checking against $h(0)=0$ the previous result has meaning, therefore accept this case.
    \end{itemize}

    It is interesting to note that the tedious derivation developed above can have
    a simpler handling if we defer substituting $h(t)-1$ to $y$, consider the following \ldots
    by cases on $\sqrt{\left(\left(y + 2\right) y\right)^{2}}$:
    \begin{itemize}
        \item $\sqrt{\left(\left(y + 2\right) y\right)^{2}}=\left(y + 2\right) y$, hence:
            \begin{displaymath} 
                \mathcal{M}_{y=h(t)-1}\left(\frac{y^{2} + 3y + 3}{{\left(y + 1\right)}^{2}} , h(t) \right) = 
                    \mathcal{M}_{h(t)}\left( \frac{1+h(t)+h(t)^2}{h(t)^2}, h(t) \right) 
            \end{displaymath} 
            since $h(0)=0$ the previous result has no meaning, therefore discard this case;
        \item $\sqrt{\left(\left(y + 2\right) y\right)^{2}}=-\left(y + 2\right) y$, hence:
            \begin{displaymath} 
                \mathcal{M}_{y=h(t)-1}\left(y^{2} + 3y + 3 , h(t) \right) = 
                    \mathcal{M}_{h(t)}\left( 1+h(t)+h(t)^2, h(t) \right) 
            \end{displaymath} 
            checking against $h(0)=0$ the previous result has meaning, therefore accept this case.
    \end{itemize}

    In both branches same definitions for $\mathcal{M}_{h(t)}$ are reached applying
    same checks, while at the same time substitution of $y$ is easier. 
    
    However, here it is the generating function which carries coefficients 
    lying on column $k$ of $\mathcal{M}_{h(t)}$:
    \begin{displaymath} 
        h(t)^{k}+h(t)^{k+1}+h(t)^{k+2}
    \end{displaymath} 


    \subsubsection{Motzkin $\mathcal{T}$ variant}

    Let $\mathcal{T}$ be the Riordan array for a variant of the Motzkin triangle defined as:
    \begin{displaymath} 
        \mathcal{T} = \left(\frac{1}{\sqrt{1-2t-3t^2}}, 
           \frac{1-t-\sqrt{1-2t-3t^2}}{2t}  \right)
    \end{displaymath} 
    computing the compositional inverse of $h$ yields:
    \begin{displaymath} 
        \hat{h}(y) = \frac{y}{1+y+y^2}
    \end{displaymath} 
    so $f(y)=d(\hat{h}(1+y))=\sqrt{\left(\frac{y^2+3y+3}{(y+2)y}\right)^{2}}$ therefore:
    \begin{displaymath} 
        \mathcal{T}_{y=h(t)-1}\left( \sqrt{\left(\frac{y^2+3y+3}{(y+2)y}\right)^{2}}, 1+y \right) = 
            \mathcal{T}_{h(t)}\left( \sqrt{\left(\frac{h(t)^2+h(t)+1}{h(t)^2-1}\right)^{2}}, h(t) \right) 
    \end{displaymath} 
    By cases on $\sqrt{\left(\frac{h(t)^2+h(t)+1}{h(t)^2-1}\right)^{2}}$:
    \begin{itemize}
        \item $\sqrt{\left(\frac{h(t)^2+h(t)+1}{h(t)^2-1}\right)^{2}}=\frac{h(t)^2+h(t)+1}{h(t)^2-1}$, hence:
            \begin{displaymath} 
                \mathcal{T}_{h(t)}\left(\frac{h(t)^2+h(t)+1}{h(t)^2-1}, h(t) \right)
            \end{displaymath} 
            requirement $h(0)=0$ doesn't raise a non-sense, so use another 
            constraint over the first component in order to have a 
            \emph{proper} array:
            \begin{displaymath}
                \left. \frac{h(t)^2+h(t)+1}{h(t)^2-1} \right|_{t=0} = -1 \not= 1 
            \end{displaymath} 
            so discard this case;
        \item $\sqrt{\left(\frac{h(t)^2+h(t)+1}{h(t)^2-1}\right)^{2}}=\frac{h(t)^2+h(t)+1}{1-h(t)^2}$, hence:
            \begin{displaymath}
                \mathcal{T}_{h(t)}\left(\frac{h(t)^2+h(t)+1}{1-h(t)^2}, h(t) \right)
            \end{displaymath} 
            requirement $h(0)=0$ doesn't raise a non-sense, so use another 
            constraint over the first component in order to have a 
            \emph{proper} array:
            \begin{displaymath}
                \left. \frac{h(t)^2+h(t)+1}{1-h(t)^2} \right|_{t=0} = 1 
            \end{displaymath} 
            which fulfill the constraint, so accept this case.
    \end{itemize}
    Now study the generating function which carries coefficients lying on column $k$
    of $\mathcal{T}_{h(t)}$:
    \begin{displaymath} 
        \frac{h(t)^{k}+h(t)^{k+1}+h(t)^{k+2}}{1-h(t)^2 }
    \end{displaymath} 


    \subsubsection{Delannoy}

    Let $\mathcal{D}$ be the Riordan array for the Delannoy triangle, defined as:
    \begin{displaymath} 
        \mathcal{D} =\left( \frac{1}{1-t}, \frac{t(1+t)}{1-t}  \right)
    \end{displaymath} 
    computing the compositional inverse of $h$ yields:
    \begin{displaymath} 
        \hat{h}(y) = \frac{\sqrt{1+6y+y^2}-y-1}{2}
    \end{displaymath} 
    so $f(y)=d(\hat{h}(1+y))=\frac{2}{4 + y - \sqrt{y^2 + 8*y + 8} }$ therefore:
    \begin{displaymath} 
        \begin{split}
            & \mathcal{D}_{y=h(t)-1}\left( \frac{2}{4+y-\sqrt{y^2+8y+8}}, 1+y \right)\\
            &= \mathcal{D}_{h(t)}\left( \frac{2}{3+h(t)-\sqrt{h(t)^2+6h(t)+1}}, h(t) \right) \\
        \end{split}
    \end{displaymath} 
    Since $h(t)^2+6h(t)+1$ isn't a perfect square, no problem arises with the previous
    derivation; now study the generating function which carries coefficients lying on column $k$
    of $\mathcal{D}_{h(t)}$:
    \begin{displaymath} 
        \frac{2h(t)^k}{3+h(t)-\sqrt{h(t)^2+6h(t)+1}}
    \end{displaymath} 

    \subsection{Some conjectures}

    In this section we try to point out the meaning of this characterization
    and some open questions about it.

    \subsubsection{Points of view}

    Let $\mathcal{R}\left(d(t),h(t)\right)$ be a Riordan array and $\mathcal{R}_{h(t)}$ be
    its characterization built using the previous method.
    
    The first point of view is to see $\mathcal{R}_{h(t)}$ as a \emph{factorization}
    of $\mathcal{R}$ in terms of $h(t)$. Namely, the structure of the characterization
    depends both on functions $d$ and $\hat{h}$, but the building block is function $h$
    alone. Moreover, second component of $\mathcal{R}_{h(t)}$ is function $h$ itself,
    therefore it seems that the $k$-fold convolution of $h$ with itself in the generic
    $k$ column expansion is common both to $\mathcal{R}$ both to $\mathcal{R}_{h(t)}$.

    The second point of view is to see $\mathcal{R}_{h(t)}$ as a \emph{schema} array.
    To understand this concept abstract over $h(t)$ and think about it as a ``plugin''
    function, one that can be substituted with any function $g(t)$ we like, to get a new array
    $\mathcal{R}^{\stackrel{g(t)}{\rightarrow}}$ (this notation is just a reminder that the array is obtained
    by plugging in $g(t)$ into the schema). It's pretty easy, and sound, to check:
    \begin{displaymath}
        \mathcal{R}^{\stackrel{h(t)}{\rightarrow}} = \mathcal{R}_{y=h(t)-1}\left( d(\hat{h}(1+y)), 1+y \right) = \mathcal{R}
    \end{displaymath}
    while considering an arbitrary function $g(t)$:
    \begin{displaymath}
        \mathcal{R}^{\stackrel{g(t)}{\rightarrow}} = \mathcal{R}_{y=g(t)-1}\left( d(\hat{h}(1+y)), 1+y \right) = 
        \left( d(\hat{h}(g(t))), g(t) \right) 
    \end{displaymath}
    observe how the first component of $\mathcal{R}^{\stackrel{g(t)}{\rightarrow}}$ depends on
    $\mathcal{R}$ by composition of functions $d$ and $\hat{h}$. So, every array seems to have
    a ``nested schema'' that allows to build new arrays.
    \\\\
    We finish with a theorem about arrays in the \emph{renewal} subgroup.

    \begin{theorem}
        Let $\mathcal{R}\left(d(t), h(t)\right)$ a Riordan array belonging
        to the \emph{renewal} subgroup, so $h(t)=td(t)$. Then:
        \begin{displaymath}
            \mathcal{R}_{h(t)}\left(A(h(t)), h(t))\right)=
            \left[\left.\mathcal{R}\left(A(y), y)\right)\right|y=h(t)\right] =
            \mathcal{R}_{y=h(t)}\left(A(y), y)\right)
        \end{displaymath}
        where $A(t)$ is the generating function over $\mathcal{R}$'s $A$-sequence 
        $\lbrace a_i \rbrace_{i\in\mathbb{N}}$. 
    \end{theorem}

    \begin{proof}
        Recall that $A$-sequence of a Riordan array $\mathcal{R}\left(d(t), h(t)\right)$
        satisfies:
        \begin{displaymath}
            h(t)=tA(h(t))
        \end{displaymath}
        By hypothesis, assume $\mathcal{R}$ belongs to the \emph{renewal} subgroup, therefore
        \begin{displaymath}
            \mathcal{R}\left(A(h(t)), h(t)\right)
        \end{displaymath}
        Let $\mathcal{R}_{h(t)}\left(g(h(t)), h(t)\right)$ be the factorization of $\mathcal{R}$,
        for some generating function $g$. Now plug $h(t)$ into $\mathcal{R}_{h(t)}$:
        \begin{displaymath}
            \mathcal{R}^{\stackrel{h(t)}{\rightarrow}} =
                \mathcal{R}\left(g(h(t)), h(t)\right)
        \end{displaymath}
        But $\mathcal{R}^{\stackrel{h(t)}{\rightarrow}} = \mathcal{R}$, therefore 
        $[g(y)=A(y)|y=h(t)]$ follows, as required.

    \end{proof}

    Looking at it deeply, it is possible to have a stronger formulation, namely the 
    converse holds indeed: the reason for this is the unique existence of an $A$-sequence
    for each Riordan array, the argument follows using $h(t)=tA(h(t))$ again .
    \\\\
    This little theorem shows a possible application of the factorization point of view.
    Consider the Motzkin array defined as:
    \begin{displaymath} 
        \mathcal{M} =\left( \frac{1-t-\sqrt{1-2t-3t^2}}{2t^2},
           \frac{1-t-\sqrt{1-2t-3t^2}}{2t}  \right)
    \end{displaymath} 
    Surely $\mathcal{M}$ is a renewal array and, being in the Riordan group, 
    has an $A$-sequence, which satisfies $A(t)=1+t+t^2$: 
    this information \emph{can't} be read from the above definition.

    Consider instead: let $h(t)=\frac{1-t-\sqrt{1-2t-3t^2}}{2t}$ be the second
    component of Motzkin array $\mathcal{M}$, which factor as follows:
    \begin{displaymath} 
        \mathcal{M}_{h(t)}\left( 1+h(t)+h(t)^2, h(t) \right) 
    \end{displaymath} 
    using this definition for $\mathcal{M}$, $A$-sequence $[A(y)=1+y+y^2|y=h(t)]$ can
    be read from the first component directly.

    \subsubsection{Inverting an array}

    Let $\mathcal{R}\left(d(t),h(t)\right)$ be a Riordan array and let 
    $\mathcal{R}_{h(t)}\left(g(h(t)),h(t)\right)$ its factorization, for some
    function $g$ in $h(t)$ (a point very important to understand: here $h(t)$ shouldn't be
    interpreted as a \emph{function}, the one in $\mathcal{R}$'s definition, instead
    abstract over it and consider it as a \emph{variable}). 
    Using rules for inversion in the Riordan group, proceed as follow:
    \begin{displaymath}
        \mathcal{R}^{-1}\left(\frac{1}{g(h(\hat{h}(t)))},\hat{h}(t)\right)=
        \left[\mathcal{R}^{-1}\left(\frac{1}{g(h(y))},y\right) | y = \hat{h}(t) \right]=
        \mathcal{R}_{\hat{h}(t)}^{-1}\left(k(\hat{h}(t)),\hat{h}(t)\right)
    \end{displaymath}
    where $k(y)=\frac{1}{g(h(y))}$, therefore we got a new array $\mathcal{T}_{\hat{h}(t)}$
    factored respect $\hat{h}(t)$ (again, $\hat{h}(t)$ plays the role of a \emph{variable},
    so don't be tempted to say $h(\hat{h}(t))=t$ as in the normal course of things \ldots).
    \\\\
    For the sake of clarity we apply the previous derivation to build the inverse of $\mathcal{F}$,
    the Fibonacci array.
    To set the stage we need function $h$, take it from the definition directly:
    \begin{displaymath}
        \begin{split}
            h(t)&=\frac{1-\sqrt{1-4t}}{2}\\
        \end{split}
    \end{displaymath}
    we need also function $g$, take it from the factorization $\mathcal{F}_{h(t)}$:
    \begin{displaymath}
        \left[g(y)=\left.\frac{1}{1-y+2y^3-y^4} \right| y=h(t)\right]
    \end{displaymath}
    we're ready to apply:
    \begin{displaymath}
        \left[\mathcal{F}^{-1}\left(1-y-y^2,y\right) | y = \hat{h}(t) \right]=
        \mathcal{F}_{\hat{h}(t)}^{-1}\left(1-\hat{h}(t)-\hat{h}(t)^2,\hat{h}(t)\right)
    \end{displaymath}
    where function $\hat{h}$ is the compositional inverse of function $h$. Observe that
    $1-y-y^2$ in the left array under variable constraint $y=\hat{h}(t)$, is obtained by
    evaluating $\frac{1}{g(h(y))}$, considering $y$ as a variable (abstracting this way $\hat{h}(t)$
    prevent to use it \emph{functionally}, otherwise $g(h(\hat{h}(k)))=g(k)$, where $k=h(t)$
    according constraint under $g$ is defined, yielding a factorization in $h(t)$, not in $\hat{h}(t)$
    as we would like to have).
    
    If the explicit definition for $\mathcal{F}^{-1}$ is desired, just plug $\hat{h}(t)=t-t^2$:
    \begin{displaymath}
        \left(\mathcal{F}_{\hat{h}(t)}^{-1}\right)^{\stackrel{\hat{h}(t)}{\rightarrow}} =
            \mathcal{F}^{-1}\left(1-t+2t^3-t^4,t-t^2\right)
    \end{displaymath}

    \subsubsection{Multiplying two arrays}
    
    To complete this alternative characterization, let us tackle the product of
    two Riordan arrays. Multiplication, the action of the Riordan group, of two arrays
    $\mathcal{A}(d_{\mathcal{A}}(t), h_{\mathcal{A}}(t))$ and 
    $\mathcal{B}(d_{\mathcal{B}}(t), h_{\mathcal{B}}(t))$ is defined as:
    \begin{displaymath}
        \mathcal{A}\mathcal{B} = \left(d_{\mathcal{A}}(t)d_{\mathcal{B}}(h_{\mathcal{A}}(t)),
            h_{\mathcal{B}}(h_{\mathcal{A}}(t))\right)
    \end{displaymath}
    Consider the factorization of $\mathcal{A}$:
    \begin{displaymath}
        \mathcal{A}_{h_\mathcal{A}(t)} \left(\gamma(h_{\mathcal{A}}(t)), h_{\mathcal{A}}(t)  \right)
    \end{displaymath}
    for some function $\gamma $ in $h_{\mathcal{A}}(t)$, and the factorization of $\mathcal{B}$:
    \begin{displaymath}
        \mathcal{B}_{h_\mathcal{B}(t)} \left(\eta(h_{\mathcal{B}}(t)), h_{\mathcal{B}}(t)  \right)
    \end{displaymath}
    for some function $\eta $ in $h_{\mathcal{B}}(t)$, respectively. Apply now the multiplication rule:
    \begin{displaymath}
        \begin{split}
            & \left(\gamma(h_{\mathcal{A}}(t)), h_{\mathcal{A}}(t)  \right)
                \left(\eta(h_{\mathcal{B}}(t)), h_{\mathcal{B}}(t)  \right) \\
            &=\left[\left.\left(\gamma(y), y  \right)
                \left(\eta(h_{\mathcal{B}}(t)), h_{\mathcal{B}}(t)  \right) \right| y=h_{\mathcal{A}}(t) \right]\\
            &=\left[\left.\left(\gamma(y)\eta(h_{\mathcal{B}}(y)), h_{\mathcal{B}}(y)  \right) \right|
                 y=h_{\mathcal{A}}(t) \right]\\
        \end{split}
    \end{displaymath}
    Stop here: it's enough to build a factorization of the product $\mathcal{A}\mathcal{B}$ 
    respect $h_{\mathcal{A}}(t)$:
    \begin{displaymath}
            \left[\left.\left(\Omega(y), h_{\mathcal{B}}(y)  \right) \right| y=h_{\mathcal{A}}(t) \right] 
            =\big(\mathcal{A}\mathcal{B}\big)_{h_{\mathcal{A}}(t)}\left(
                \Omega(h_{\mathcal{A}}(t)), h_{\mathcal{B}}(h_{\mathcal{A}}(t))  \right)
    \end{displaymath}
    where $\left[\Omega(y)= \gamma(y)\eta(h_{\mathcal{B}}(y))| y=h_{\mathcal{A}}(t) \right]$. 
    Nonetheless, from were we stopped, it's possible to factor $\mathcal{A}\mathcal{B}$ respect $h_{\mathcal{B}}(t)$ in
    a similar way, this time abstracting over $h_{\mathcal{B}}(y)$, remembering to track $y=h_{\mathcal{A}}(t)$:
    \begin{displaymath}
        \begin{split}
            &\left[\left.\left(\gamma(y)\eta(h_{\mathcal{B}}(y)), h_{\mathcal{B}}(y)  \right) \right|
                 y=h_{\mathcal{A}}(t) \right]\\
            &=\left.\left[\left.\left(\gamma(\hat{h}_{\mathcal{B}}(k))\eta(k), k  \right) \right|
                 k=h_{\mathcal{B}}(y) \right]\right|_{y=h_{\mathcal{A}}(t)}\\
            &=\left.\left[\left.\left(\Theta(k), k  \right) \right| k=h_{\mathcal{B}}(y) \right]\right|_{y=h_{\mathcal{A}}(t)}\\
            &=\textcolor{red}{\left[\left.\left(\Theta(k), k  \right) \right| 
                h_{\mathcal{B}}(\hat{h}_{\mathcal{A}}(\hat{h}_{\mathcal{B}}(k)))=h_{\mathcal{B}}(t) \right]} 
                \marginnote{this writing really abstract over $h_{\mathcal{B}}(t)$ making dependency on $y$ vanish}\\
            &=\left.\big(\mathcal{A}\mathcal{B}\big)_{h_{\mathcal{B}}(y)}\left(
                \Theta(h_{\mathcal{B}}(y)), h_{\mathcal{B}}(y)  \right)\right|_{y=h_{\mathcal{A}}(t)}
        \end{split}
    \end{displaymath}
    where $\left.\left[\left.\Theta(k)=\gamma(\hat{h}_{\mathcal{B}}(k))\eta(k) \right| 
        k=h_{\mathcal{B}}(y) \right]\right|_{y=h_{\mathcal{A}}(t)}$.

    Observe that for the latter factorization, it is necessary to compute function $\hat{h}_{\mathcal{B}}$, 
    the compositional inverse of function $h_{\mathcal{B}}$.
    \\\\
    For the sake of clarity we apply the previous derivation to the product $\mathcal{P}\mathcal{F}$, namely
    we are multiplying Pascal and Fibonacci arrays, \emph{in the given order}, providing 
    both $\big(\mathcal{P}\mathcal{F}\big)_{h_{\mathcal{P}}(t)}$ 
    both $\left.\big(\mathcal{P}\mathcal{F}\big)_{h_{\mathcal{F}}(y)}\right|_{y=h_{\mathcal{P}}(t)}$.

    Recall how $\mathcal{P}$ and $\mathcal{F}$ are factored:
    \begin{displaymath}
        \begin{split}
            &\mathcal{P}_{h_{\mathcal{P}}(t)}\left( 1+h_{\mathcal{P}}(t), h_{\mathcal{P}}(t) \right)
                \text{ where } h_{\mathcal{P}}(t) = \frac{t}{1-t}\\
            &\mathcal{F}_{h_{\mathcal{F}}(t)}\left( \frac{1}{1-h_{\mathcal{F}}(t)+
                2h_{\mathcal{F}}(t)^3-h_{\mathcal{F}}(t)^4}, h_{\mathcal{F}}(t) \right)
                    \text{ where } h_{\mathcal{F}}(t) = \frac{1-\sqrt{1-4t}}{2}\\
        \end{split}
    \end{displaymath}
    and recognize the following functions under variable constraint (in the following, $y$
    is a ``local'' variable, \emph{it's not shared} among the two definitions):
    \begin{displaymath}
        \begin{split}
            &\left[\left.\gamma(y) = 1+y \right| y=h_{\mathcal{P}}(t) \right]\\
            &\left[\left.\eta(y) = \frac{1}{1-y+2y^3-y^4} \right| y=h_{\mathcal{F}}(t) \right]\\
        \end{split}
    \end{displaymath}

    Toward $\big(\mathcal{P}\mathcal{F}\big)_{h_{\mathcal{P}}(t)}$, compute $\Omega$ function:
    \begin{displaymath}
        \left[\Omega(y)= \gamma(y)\eta(h_{\mathcal{F}}(y))| y=h_{\mathcal{P}}(t) \right]
            = \left[\Omega(y)= \frac{1+y}{1-y-y^2}| y=h_{\mathcal{P}}(t) \right]
    \end{displaymath}
    therefore tackle the first request:
    \begin{displaymath}
        \big(\mathcal{P}\mathcal{F}\big)_{h_{\mathcal{P}}(t)} \left(\frac{1+
            h_{\mathcal{P}}(t)}{1-h_{\mathcal{P}}(t)-h_{\mathcal{P}}(t)^2}, \frac{1-\sqrt{1-4h_{\mathcal{P}}(t)}}{2} \right)
    \end{displaymath}

    Toward $\left.\big(\mathcal{P}\mathcal{F}\big)_{h_{\mathcal{F}}(t)}\right|_{y=h_{\mathcal{P}}(t)}$, compute $\Theta$ function:

    \begin{displaymath}
        \begin{split}
            &\left.\left[\left.\Theta(k)=\gamma(\hat{h}_{\mathcal{F}}(k))\eta(k) \right| k=h_{\mathcal{F}}(y) \right]\right|_{y=h_{\mathcal{P}}(t)}\\
            &= \left.\left[\left.\Theta(k)=\frac{1+k-k^2}{1-k+ 2k^3 - k^4} \right| k=h_{\mathcal{F}}(y) \right]\right|_{y=h_{\mathcal{P}}(t)}\\
        \end{split}
    \end{displaymath}
    where $\hat{h}_{\mathcal{F}}(y)=y-y^2$, therefore tackle the second request:
    \begin{displaymath}
        \left.\big(\mathcal{P}\mathcal{F}\big)_{h_{\mathcal{F}}(y)} \left(
            \frac{1+h_{\mathcal{F}}(y)-h_{\mathcal{F}}(y)^2}{1-h_{\mathcal{F}}(y)+ 2h_{\mathcal{F}}(y)^3 - h_{\mathcal{F}}(y)^4} ,
            h_{\mathcal{F}}(y) \right)\right|_{y=h_{\mathcal{P}}(t)}
    \end{displaymath}
    
    Little check plugging in function $h_{\mathcal{P}}(t)$:
    \begin{displaymath}
        \left(\big(\mathcal{P}\mathcal{F}\big)_{h_{\mathcal{P}}(t)}\right)^{\stackrel{h_{\mathcal{P}}(t)}{\rightarrow}}
            = \big(\mathcal{P}\mathcal{F}\big)\left(\frac{1-t}{1-3t+t^2}, \frac{1}{2}-\frac{1}{2}\sqrt{\frac{1-5t}{1-t}} \right)
    \end{displaymath}
    on the other hand, plugging in function $h_{\mathcal{F}}(y)$, where $y=h_{\mathcal{P}}(t)$:
    \begin{displaymath}
        \left.\left(\big(\mathcal{P}\mathcal{F}\big)_{h_{\mathcal{F}}(y)}\right)^{\stackrel{h_{\mathcal{F}}(y)}{\rightarrow}}\right|_{y=h_{\mathcal{P}}(t)}
            = \left.\big(\mathcal{P}\mathcal{F}\big)\left(\frac{1+y}{1-y-y^2}, \frac{1-\sqrt{1-4y}}{2} \right)\right|_{y=h_{\mathcal{P}}(t)}
    \end{displaymath}


    

    \subsubsection{Open questions}

    Under previous insights, we ask respectively:
    \begin{enumerate}
        \item let $\mathcal{R}_{h(t)}=\left(g(h(t)), h(t)\right)$ a factorization of $\mathcal{R}$,
            and consider the series expansion of $[g(y)=g_0 + g_1 y + g_2 y^2 + \ldots|y=h(t)]$: 
            what's the interpretation of coefficients $\lbrace g_i\rbrace_{i\in\mathbb{N}}$? 
            
            Last theorem shows that, provided $\mathcal{R}=\left(d(t), td(t)\right)$, then 
            $[g(y)=A(y)|y=h(t)]$ where $A(t)$ is $\mathcal{R}$'s A-sequence: 
            does exist a deep relation among those sequences for arbitrary arrays?   
            For instance, what about Fibonacci array $\mathcal{F}$: 
            \begin{displaymath}
                \begin{split}
                    \big[ g_{\mathcal{F}}(y) &= 1 + y + y^{2} - y^{3} -2y^{4} 
                    -3 y^{5}  +3 y^{7} \\
                    &+7 y^{8} +4 y^{9} + \mathcal{O}\left(y^{10}\right) | y=h_{\mathcal{F}}(t) \big]
                \end{split}
            \end{displaymath}
            and about Delannoy array $\mathcal{D}$: 
            \begin{displaymath}
                \begin{split}
                    \big[ g_{\mathcal{D}}(y) &= 1 + y - y^{2} + 3 y^{3} -11y^{4} + 45 y^{5} -197y^{6}\\ 
                    &+ 903 y^{7} -4279y^{8} + \mathcal{O}\left(y^{9}\right)| y=h_{\mathcal{D}}(t) \big]
                \end{split}
            \end{displaymath}
        \item let $\mathcal{P}$ and $\mathcal{C}$ be Pascal and Catalan arrays, respectively: 
            what does $\mathcal{C}^{\stackrel{\frac{t}{1-t}}{\rightarrow}}$ count? 
            More generally, chosen two Riordan arrays $\mathcal{A}$ and $\mathcal{B}$, 
            $\mathcal{A}^{\stackrel{h_{\mathcal{B}}(t)}{\rightarrow}}$ also has a combinatorial meaning? 
            So does $\mathcal{B}^{\stackrel{h_{\mathcal{A}}(t)}{\rightarrow}}$? What about considering
            combinations involving  $\mathcal{A}^{-1}$ and $\mathcal{B}^{-1}$ too?


        \item \added{let $\mathcal{R}(d(t),h(t))$ be a Riordan array in 
            natural notation. If function $\hat{h}$, the compositional inverse
            of function $h$, has the following structure:}
            \begin{displaymath}
                \added{\hat{h}(y) = \frac{y}{\Pi(y)}}
            \end{displaymath}
            \added{
            where $\Pi$ is a polynomial such that $\Pi(0)\not=0$, the question is:
            is it always the case that there exists a sequence of polynomials
            $\lbrace \Omega_{i} \rbrace_{i\in\mathbb{N}}$ such
            that $\mathcal{R}$'s $A$-sequence can be be factored respect
            function $\hat{h}$ as:}
            \begin{displaymath}
                \added{
                    \left.\left[
                        A_{\mathcal{R}}(y) = \sum_{i \geq0}{
                            \left(\frac{[t^{1+i}]d(t)h(t)}
                                {\Pi(y)}\right)
                            \hat{h}(y)^{i}} 
                            \right| y = h(t) \right]
                }
            \end{displaymath}
            \added{in other words, the sequence of coefficients of the function defining
            the second column of array $\mathcal{R}$, namely function 
            $d$ times function $h$, shifted by \emph{one} position, does occur in
            the given factorization?}

    \end{enumerate}

    \subsubsection{\added[id=sid]{An hint\ldots}}
    
    \added[id=sid]{In this question we offer an hint to tackle question number $1$
    asked in previous enumeration. Let $\mathcal{R}_{h(t)}(\gamma(h(t)), h(t))$
    be a Riordan array written in factored notation, for some function $\gamma$. 
    Now, with abuse of notation, do a \emph{standard} matrix-vector product, namely
    consider $\mathcal{R}_{h(t)}$ a matrix: multiply it by a vector $\vect{\omega}$
    whose coefficients are defined by a sequence $\lbrace \omega_i \rbrace_{i\in\mathbb{N}}$
    and set equal to a vector $\vect{a}$ whose coefficients are defined by $\mathcal{R}$'s
    $A$-sequence. Formally:
    }
    \begin{displaymath}
        \mathcal{R}_{h(t)}\left[\begin{array}{c} \omega_0 \\ \omega_1 \\ \omega_2 \\ \vdots \end{array}\right] =
            \left[\begin{array}{c} a_0 \\ a_1 \\ a_2 \\ \vdots \end{array}\right]
    \end{displaymath}
    \added[id=sid]{Interpreting columns of $\mathcal{R}_{h(t)}$ and vector $\vect{a}$ via
    corresponding generating functions, rewrite as follow: }
    \begin{displaymath}
        \begin{split}
                \omega_0\,\gamma(h(t))\,h(t)^{0} + 
                \omega_1\,\gamma(h(t))\,h(t)^{1} + 
                \omega_2\,\gamma(h(t))\,h(t)^{2} + 
                \ldots &= A(t) \\
                \gamma(h(t))\left(\omega_0\,h(t)^{0} + 
                \omega_1\,h(t)^{1} + 
                \omega_2\,h(t)^{2} + 
                \ldots \right) &= A(t) \\
                \gamma(h(t))\,\Omega(h(t)) &= A(t) \\
        \end{split}
    \end{displaymath}
    \added[id=sid]{where functions $A$ and $\Omega$ are fps over sequences
    $\lbrace a_i \rbrace_{i\in\mathbb{N}}$ and
    $\lbrace \omega_i \rbrace_{i\in\mathbb{N}}$, respectively. Note that abstracting
    over function $h$ yield:}
    \begin{displaymath}
        \left.\left[
            \gamma(y)\,\Omega(y) = A(\hat{h}(y)) \right| y = h(t) \right]
    \end{displaymath}
    \added[id=sid]{but this relationship is quite difficult since introduces function $\hat{h}$,
    the compositional inverse of function $h$. Therefore, function
    $\gamma$, parameterized by function $h$, is related to $\mathcal{R}$'s
    $A$-sequence, parameterized over variable $t$, by the existence of 
    a function $\Omega$, parameterized over function $h$, such that:}
    \begin{displaymath}
        \gamma(h(t))\,\Omega(h(t)) = A(t) 
    \end{displaymath}
    \added[id=sid]{an hint has been provided, in turn another question arises: \emph{there
    exists a smart way to compute function $\Omega$}? If there exists such a method, then
    $\mathcal{R}$'s $A$-sequence could be computed easily, since function $\gamma$ 
    is read directly from the factorization, for \emph{any} Riordan array\ldots}

    \subsection{A theorem when $\mathcal{R}(d(t), td(t))$}

    By observing previous results, it seems there's a relation
    about the shape of a Riordan array $\mathcal{R}(d(t), td(t))$ 
    and the shape of column $k$ generating function. 
    
    The question is: does exist a sequence $\lbrace s_i \rbrace_{i \in \mathbb{N}}$ 
    of coefficients such that column $k$ generating function is $S(h(t)^{j_k})$, where $S$
    is a formal power series over the sequence? In expanded form: 
    \begin{displaymath}
        \added{d(t)h(t)^k = }s_0h(t)^{j_k} + s_1 h(t)^{j_k+1} + s_2 h(t)^{j_k+2} + 
            \ldots + s_i h(t)^{j_k+i} + \ldots
    \end{displaymath}
    for some $j_k \in \mathbb{Z}$, where $j_k$ is a notation to denote an index $j$ 
    which depends on $k$.

    \begin{proof}

    Since $h(t)=td(t)$, let $\hat{h}(y)$ be its compositional inverse, therefore:
    \begin{displaymath}
        y = h(\hat{h}(y)) = \hat{h}(y)d(\hat{h}(y)) 
    \end{displaymath}
    so:
    \begin{displaymath}
        \hat{h}(y) = \frac{y}{d(\hat{h}(y)) }
    \end{displaymath}
    and evaluating at $1+y$:
    \begin{displaymath}
        d(\hat{h}(1+y)) = \frac{1+y}{ \hat{h}(1+y)}
    \end{displaymath}
    Recall the definition of the characterization $\mathcal{R}_{y=h(t)-1}\left( f(y), 1+y \right)$,
    where $f(y)=d(\hat{h}(1+y))$, so the column $k$ generating function can be rewritten as:
    \begin{displaymath}
        \frac{(1+y)^{k+1}}{ \hat{h}(1+y)}
    \end{displaymath}
    Let $k(y)$ be the formal power series with coefficients in 
    $\lbrace k_i \rbrace_{i\in\mathbb{N}}$ such that :
    \begin{displaymath}
        k(y) = \frac{1}{ \hat{h}(1+y)} = \sum_{i\geq 0}{k_i}y^{i}
    \end{displaymath}
    Since $(1+y)^{k+1}$ has a binomial shape:
    \begin{displaymath}
        (1+y)^{k+1} = \sum_{s= 0}^{k+1}{{k+1}\choose{s}}y^{s}= \sum_{s\geq 0}{{k+1}\choose{s}}y^{s}
    \end{displaymath}
    because ${{n}\choose{m}}$ vanishes if $n<m$. Therefore $k(y)(1+y)^{k+1}$ is a convolution:
    \begin{displaymath}
        k(y)(1+y)^{k+1} = \sum_{s\geq 0}{\sum_{j=0}^{s}{k_j {{k+1}\choose{s-j}}} y^{s}} = 
            \sum_{s\geq 0}{\alpha_{s}^{(k+1)} y^{s}}
    \end{displaymath}
    where $\alpha_{s}^{(k+1)} \in \mathbb{Z}$ such that $\alpha_{s}^{(k+1)}=\sum_{j=0}^{s}{k_j {{k+1}\choose{s-j}}}$.
    By variable substitution $y = h(t)-1$ rewrite as:
    \begin{displaymath}
        \sum_{s\geq 0}{\alpha_{s}^{(k+1)} y^{s}}
            = \sum_{s\geq 0}{\alpha_{s}^{(k+1)} (h(t)-1)^{s}}
            = \sum_{s\geq 0}{(-1)^{s}\alpha_{s}^{(k+1)} (1-h(t))^{s}}
    \end{displaymath}
    calling $\beta_{s}^{(k+1)}=(-1)^{s}\alpha_{s}^{(k+1)}$ and expanding $(1-h(t))^{s}$
    as a binomial in $h(t)$ yield:
    \begin{displaymath}
        \sum_{s\geq 0}{\beta_{s}^{(k+1)} {\sum_{r=0}^{s}{(-1)^{r}{{s}\choose{r}} h(t)^{r}}}} =
        \sum_{s\geq 0}{ \sum_{r=0}^{s}{\beta_{s}^{(k+1)}(-1)^{r}{{s}\choose{r}} h(t)^{r}}} =
    \end{displaymath}
    calling $\gamma_{s,r}^{(k+1)}=\beta_{s}^{(k+1)}(-1)^{r}{{s}\choose{r}}$ and making 
    unbounded the inner sum yield: 
    \begin{displaymath}
        \sum_{s\geq 0}{ \sum_{r=0}^{s}{\beta_{s}^{(k+1)}(-1)^{r}{{s}\choose{r}} h(t)^{r}}} =
        \sum_{s\geq 0}{ \sum_{r\geq 0}{\gamma_{s,r}^{(k+1)} h(t)^{r}}} =
        \sum_{r\geq 0}{ \left(\sum_{s\geq 0}{\gamma_{s,r}^{(k+1)} }\right) h(t)^{r}}
    \end{displaymath}
    calling $\nu_{r}^{(k+1)}=\sum_{s\geq 0}{\gamma_{s,r}^{(k+1)} }$, the following equation
    joins our starting point with the requested argument:
    \begin{displaymath}
        \frac{(1+y)^{k+1}}{ \hat{h}(1+y)} = 
        \frac{(1+y)(1+y)^{k}}{ \hat{h}(1+y)} = 
        \frac{h(t)h(t)^{k}}{ \hat{h}(h(t))} = 
        d(t)h(t)^{k} = \sum_{r\geq 0}{ \nu_{r}^{(k+1)} h(t)^{r}}
    \end{displaymath}

    \end{proof}

    \subsection{A generalization of the $A$-sequence concept}

    Every Riordan array $\mathcal{R}$ has a particular sequence 
    $\lbrace a_i\rbrace_{i\in\mathbb{N}}$,
    called $A$-sequence (and denote with $A(t)$ the fps over it),
    such that uniquely characterize it (to be precise another sequence
    $\lbrace z_i\rbrace_{i\in\mathbb{N}}$, called $Z$-sequence, is needed 
    to fulfill the very first column, together with $d_{00}$, the root element), 
    capturing the way every element $d_{n+1,k+1}$ can be written as a linear combination
    of elements lying on the previous row, formally:
    \begin{displaymath}
        d_{n+1,k+1} = a_{0}d_{n,k} +a_{1}d_{n,k+1} +a_{2}d_{n,k+2} + 
            \ldots + a_{j}d_{n,k+j}
    \end{displaymath}
    where $j = n-k$. In this section we would like to offer a generalization
    of this ``combinatorial device'', providing a machinery to build sequences 
    that combine coefficients, possibly lying on arbitrary rows, as desired.
    Finally, a connection with $A$-matrix concept is explored, leaving an open 
    question.


    What follows doesn't use the alternative characterization developed in 
    previous section, we put it here because use a \emph{column oriented}
    approach, as used in the characterization. For the sake of simplicity,
    however, we start from an array $\mathcal{R}(d(t),h(t))$ and its 
    factorization $\mathcal{R}_{h(t)}(g(h(t)), h(t))$, for some function $g$.
    
    \subsubsection{Localizing $A$-sequences}

    Consider the following question: there exists a sequence 
    $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ of coefficients 
    such that the generic element $d_{n+1,k+1}\in\mathcal{R}$ can be written
    as a linear combination of \emph{all} other elements $d_{n,j}$ 
    lying on the previous row, namely for all $j\in\lbrace0,1,2,\ldots,n\rbrace$? 
    Later we ask a more general question, for now tackle the current one.

    The previous statement can be written in a compact way, or \emph{column-wise}, as:
    \begin{displaymath}
        g(h(t))h(t)^k = \sum_{i\geq0}{\gamma_i\,t\,g(h(t)) h(t)^i}\\
    \end{displaymath}
    To see why, recall that generating function of a generic column 
    $k$ is $g(h(t))h(t)^k$ and imagine that series written vertically, 
    with increasing degree of $t$ from top to bottom.
    The required constraint on coefficient of $t^n$, namely $d_{nk}$, 
    to be a linear combination of elements lying on the previous row 
    can be satisfied if we \emph{shift downward} every column,
    namely multiplying each one by $t$, and combining them using coefficients
    from $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$. 
    We learned this trick from Shapiro introductory article \emph{The Riordan group}.

    Simplifying $g(h(t))$ shows that using the factored representation or
    the natural one doesn't make any difference, therefore:
    \begin{displaymath}
        h(t)^k = t \sum_{i\geq 0}{\gamma_i\,h(t)^i} = t \Gamma(h(t))
    \end{displaymath}
    where function $\Gamma$ is a fps over sequence 
    $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$.
    Doing a change of variable to abstract over $h(t)$, its possible to
    structure the basic for a generic schema (or \emph{device} if you please):
    \begin{displaymath}
        \left[y^{k} = \hat{h}(y) \Gamma(y) \big| y = h(t) \right]
    \end{displaymath}
    
    Before going on, just use the previous device against known arrays. Take 
    array $\mathcal{C}$, so $\hat{h}_{\mathcal{C}}(y) = y-y^2$, hence:
    \begin{displaymath}
        \left[\frac{y^{k-1}}{1-y} =  \Gamma(y) \big| y = h(t) \right]\\
    \end{displaymath}
    so sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ satisfies:
    \begin{displaymath}
        \lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}} = 
            \left(\underbrace{\gamma_{0}=0,\ldots,\gamma_{k-2}=0}_{k-1 \text{ zeros}},
                \underbrace{\gamma_{k-1}=1, \ldots}_{\text{infinitely many ones}} \right)
    \end{displaymath}
    what it says is: ``in order to get $d_{nk}\in\mathcal{C}$ take the sum 
    $\sum_{i=k-1}^{n-1}{d_{n-1,i}}$'', as known. Motzkin's turn, 
    $\hat{h}_{\mathcal{M}}(y) = \frac{y}{1+y+y^2}$, hence:
    \begin{displaymath}
            \left[\Gamma(y)=y^{k-1}+y^{k}+y^{k+1}\big| y = h(t) \right]
    \end{displaymath}
    what it says is: ``in order to get $d_{nk}\in\mathcal{M}$ take the sum 
    $d_{n-1,k-1}+d_{n-1,k}+d_{n-1,k+1}$'', as known.
    
    What we've done is nothing more nothing less than writing $A$-sequences 
    in a more generic format, putting evidence on the \emph{local} meaning 
    of the combination: it is explicitly written the dependency of 
    elements belonging to a column $k$. On the other hand, natural $A$-sequences 
    are stated with a fixed start index in mind, namely $k-1$ if combining 
    for elements in a column $k$.

    It is possible to get the natural $A$-sequence back by requiring that 
    combination of elements lying on the previous row starts at index $k-1$, formally:
    \begin{displaymath}
        \left[y^{k} = y^{k-1}\,\hat{h}(y)\,\Gamma(y) \big| y = h(t) \right] = 
        \left[y = \hat{h}(y)\,\Gamma(y) \big| y = h(t) \right]
    \end{displaymath}
    since $h(t) = t\,A(h(t))$, then formal power series 
    $\Gamma(y)$ and $A(t)$ are defined over the same sequence, as desired.
    \\\\
    Here there are a couple of applications. 

    What if we ask: find sequences $_{k}\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ 
    such that an element $d_{nk}\in\mathcal{C}$ combines elements lying on 
    row three lines above, starting from column index $2$, 
    namely $d_{n-3,k}$ for all $k\in\lbrace 2,\ldots,n-3\rbrace$. 
    Set the device:
    \begin{displaymath}
        \left[y^{k} = y^{2}\,\hat{h}(y)^3\,\Gamma(y) \big| y = h(t) \right] =
            \left[\frac{y^{k-5}}{(1-y)^3} = \Gamma(y) \big| y = h(t) \right]
    \end{displaymath}

    Two quick checks: in order to find $d_{7,5}$, chosen at random, 
    expand function $\Gamma$ with $k=5$:
    \begin{displaymath}
        \left.\left[\Gamma(y)=1 + 3y + 6y^2 + 10y^3 + 15y^4 + \mathcal{O}(y^5) 
            \big| y = h(t) \right]\right|_{k=5}
    \end{displaymath}
    therefore $d_{7,5}=d_{4,2} + 3\,d_{4,3} + 6\,d_{4,4}$, 
    instantiating $27 = 9 + 3\cdot4 + 6\cdot1$, which holds.
    Just another element, say $d_{9,7}$, so expand function $\Gamma$ with $k=7$:
    \begin{displaymath}
        \left.\left[\Gamma(y)=y^2 + 3y^3 + 6y^4 + 10y^5 +  \mathcal{O}(y^6) 
            \big| y = h(t) \right]\right|_{k=7}
    \end{displaymath}
    therefore $d_{9,7}=d_{6,4} + 3\,d_{6,5} + 6\,d_{6,6}$, 
    instantiating $44 = 20 + 3\cdot6 + 6\cdot1$, which holds.
    It's interesting to observe the following fact: while a natural $A$-sequence
    says how to combine starting always from the previous column index, with
    this generalization we got the same coefficients for combining, while
    an additional information from what column index the combination should start.

    The previous two checks shows exactly this aspect: for column index $k=5$
    combination starts at column index $2$, while for column index $k=7$ combination
    starts at column index $4$.
    \\\\
    One last application, before the interlude: 
    find a sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ such that 
    an element $d_{nk}\in\mathcal{M}$ combines \emph{all} elements lying on 
    the next row, namely $d_{n+1,k}$ for all $k\in\lbrace0,\ldots,n+1\rbrace$.
    The first step is always setting the device:
    \begin{displaymath}
        \left[y^{k} = \hat{h}(y)^{-1}\,\Gamma(y) \big| y = h(t) \right]=
            \left[ \frac{y^{k + 1}}{y^2 + y + 1} = \Gamma(y) \big| y = h(t) \right]
    \end{displaymath}
    in order to find $d_{6,3}$, chosen at random, expand function $\Gamma$ with $k=3$:
    \begin{displaymath}
        \left.\left[\Gamma(y)=y^4 -y^5 + y^7 -y^8 +y^{10} + \mathcal{O}(y^{11}) 
            \big| y = h(t) \right]\right|_{k=3}
    \end{displaymath}
    therefore $d_{6,3}=d_{7,4} - d_{7,5} + d_{7,7}$, instantiating $44 = 70 -27 +1$, 
    which holds. Just another element, say $d_{8,1}$, so expand function 
    $\Gamma$ with $k=1$:
    \begin{displaymath}
        \left.\left[\Gamma(y)=y^2 -y^3 + y^5 -y^6 + y^8 -y^9 + y^{11} + 
            \mathcal{O}(y^{12}) \big| y = h(t) \right]\right|_{k=1}
    \end{displaymath}
    therefore $d_{8,1}=d_{9,2} - d_{9,3} + d_{9,5}- d_{9,6}+ d_{9,8}- d_{9,9}$, 
    instantiating $512 = 1422 -1140 +369 -147 +9 -1$, which holds.
    \\\\
    As a final remark, under the insights of two solved exercises, is that a
    sequence found using this approach, knows which elements to combine and which
    ones to discard, we're required to supply the set of available elements only.


    \subsubsection{Interlude: let's generalize}
    
    Previous applications shows a pattern that can be pointed out looking at 
    the generic device for a Riordan array $\mathcal{R}$ where 
    function $h$ is its second component and function $\hat{h}$ its compositional
    inverse:
    \begin{displaymath}
        \left[y^{k} = \hat{h}(y) \Gamma(y) \big| y = h(t) \right]
    \end{displaymath}
    on the left hand side of the variable substitution block there's \emph{an
    equation}, where function $\Gamma$ is the unknown. In this format, 
    a constraint is stated: let $d_{nk}\in\mathcal{R}$ be a generic element, 
    then a \emph{localized} sequence 
    $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ respect column $k$ exists, which
    combines all elements lying on the previous row $n-1$.

    Since we're dealing with an equation, we can augment it as desired in order to
    constrain over additional facts. For instance, consider the following question:
    find a sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ such that 
    an element $d_{nk}\in\mathcal{R}$ combines \emph{all} elements lying on 
    \emph{some} row $r_\alpha$, with the additional property to add the combination of 
    elements, defined by a sequence $\lbrace \theta_{i} \rbrace_{i\in\mathbb{N}}$, 
    lying on \emph{some different} row $r_\beta$. Formally, $\alpha,\beta\in\mathbb{Z}$ 
    and $\alpha \not=\beta$, so set the device as usual:
    \begin{displaymath}
        \left[y^{k} = \hat{h}(y)^{\alpha} \Gamma(y) + \hat{h}(y)^{\beta} \Theta(y) \big| y = h(t) \right]
    \end{displaymath}
    Nonetheless its generality, its not the best one: to be truly general,
    we should introduce two new parameters $c_\mu$ and $c_\nu$, which allow
    to fix the column index from where the combinations denoted by functions
    $\Gamma$ and $\Theta$ start, respectively. Here is the most general device:
    \begin{displaymath}
        \left[y^{k} = y^{c_\mu}\hat{h}(y)^{\alpha} \Gamma(y) + 
            y^{c_\nu}\hat{h}(y)^{\beta} \Theta(y) \big| y = h(t) \right]
    \end{displaymath}

    Try to make the generalization at work:
    find a sequence $\lbrace \gamma_{i} \rbrace_{i\in\mathbb{N}}$ such that 
    an element $d_{nk}\in\mathcal{D}$, in the Delannoy array, 
    combines \emph{all} elements lying on 
    the next row, namely $n+1$, in addition to the
    combination of elements lying two row above, namely $n-2$, 
    defined as their sum, simply. 

    In order to set the device, we need $\hat{h}_{\mathcal{D}}$:
    \begin{displaymath} 
        \hat{h}_{\mathcal{D}}(y) = \frac{\sqrt{1+6y+y^2}-y-1}{2}
    \end{displaymath} 
    and build function $\Theta$ from the additional requirement:
    \begin{displaymath} 
        \Theta(y) = \frac{1}{1-y}
    \end{displaymath} 
    now we're ready:
    \begin{displaymath}
    \begin{split}
        &\left[y^{k} = \hat{h}_{\mathcal{D}}(y)^{-1} \Gamma(y) + 
            \hat{h}_{\mathcal{D}}(y)^{2}\frac{1}{1-y} \big| y = h(t) \right]\\
        &= \frac{y^{3} + {\left(y^{2} - 1\right)} y^{k} + 6 \, y^{2} - {\left({\left(y - 1\right)} y^{k} + y^{2} + 3 \, y + 1\right)} \sqrt{y^{2} + 6 \, y + 1} + 6 \, y + 1}{2 \, {\left(1-y\right)}}\\
    \end{split}
    \end{displaymath}
    in order to find $d_{8,1}$, chosen at random, expand function $\Gamma$ with $k=1$:
    \begin{displaymath}
        \left.\left[\Gamma(y)=y^2 -3y^3 + 11y^4  -47y^5 + 211y^6 -987y^7 + 4747y^8 
            -23335y^9 + \mathcal{O}(y^{10}) \big| y = h(t) \right]\right|_{k=1}
    \end{displaymath}
    therefore $d_{8,1}=d_{9,2} -3\,d_{9,3} +11\,d_{9,4}-47\,d_{9,5} 
        +211\,d_{9,6} -987\,d_{9,7} +4747\,d_{9,8}-23335\,d_{9,9}+\epsilon$,
        where $\epsilon = d_{6,0}+d_{6,1}+d_{6,2}+d_{6,3}+d_{6,4}+d_{6,5}+d_{6,6} = 
                2(d_{6,0}+d_{6,1}+d_{6,2})+d_{6,3} = 2(1 + 11 + 41) + 63 = 169$: 
        instantiating $15 = 113 -3\cdot377 +11\cdot681 -47\cdot681 +211\cdot377
            -987\cdot113 +4747\cdot17 -23335 + \epsilon = -154 + 169$, which holds.

    It's interesting to observe that function $\Gamma$ above, an algebraic one,
    produces sequences that use different coefficients for different values of $k$,
    and we observe a curious pattern for increasing values of 
    $k\in\lbrace 0,\ldots,10 \rbrace$:
    \begin{lenghtydisplaymath}
        \begin{split}
            &\left.\left[\Gamma(y)=
            1 y + {(-2)} y^{2} + 5 y^{3} + {(-17)} y^{4} + 65 y^{5} + {(-273)} y^{6} + 1213 y^{7} + {(-5617)} y^{8} + 26809 y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=0}\\
            &\left.\left[\Gamma(y)=
            1 y^{2} + {(-3)} y^{3} + 11 y^{4} + {(-47)} y^{5} + 211 y^{6} + {(-987)} y^{7} + 4747 y^{8} + {(-23335)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=1}\\
            &\left.\left[\Gamma(y)=
            3 y^{4} + {(-19)} y^{5} + 99 y^{6} + {(-503)} y^{7} + 2547 y^{8} + {(-12971)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=2}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 6 y^{4} + {(-27)} y^{5} + 127 y^{6} + {(-615)} y^{7} + 3031 y^{8} + {(-15171)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=3}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-24)} y^{5} + 119 y^{6} + {(-587)} y^{7} + 2919 y^{8} + {(-14687)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=4}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 122 y^{6} + {(-595)} y^{7} + 2947 y^{8} + {(-14799)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=5}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-592)} y^{7} + 2939 y^{8} + {(-14771)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=6}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-593)} y^{7} + 2942 y^{8} + {(-14779)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=7}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-593)} y^{7} + 2941 y^{8} + {(-14776)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=8}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-593)} y^{7} + 2941 y^{8} + {(-14777)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=9}\\
            &\left.\left[\Gamma(y)=
            {(-1)} y^{3} + 5 y^{4} + {(-25)} y^{5} + 121 y^{6} + {(-593)} y^{7} + 2941 y^{8} + {(-14777)} y^{9} + \mathcal{O}\left(y^{10}\right)
                \big| y = h(t) \right]\right|_{k=10}\\
        \end{split}
    \end{lenghtydisplaymath}

    From $k=3$, it seems that a coefficient stabilizes in the expansion, pretty nice.
    To finish this section involving Delannoy triangle, we report its natural
    $A$-sequence:
    \begin{lenghtydisplaymath}
        \left.\left[\Gamma(y)=
        1 + 2 y + {(-2)} y^{2} + 6 y^{3} + {(-22)} y^{4} + 90 y^{5} + {(-394)} y^{6} + 1806 y^{7}  + \mathcal{O}\left(y^{8}\right)
            \big| y = h(t) \right]\right|_{k=1}\\
    \end{lenghtydisplaymath}

    \subsubsection{$A$-matrix connection}

    Is the previous device the most general one? Really is it? 
    We lie. In this section we enhance the last version to 
    find an interesting connection with 
    the $A$-matrix concept of a Riordan array $\mathcal{R}$, 
    introduced and developed by Merlini, Rogers, Sprugnoli and Verri.
    \\\\
    Let $\lbrace\Omega_{i}\rbrace_{i\in\mathbb{N}}$ be a collection of formal
    power series and assume we would like to \emph{not} localize them (a-l\`a natural 
    $A$-sequence) in order to combine elements lying on the previous row, the previous
    but one and so on \ldots hence, respect an element $d_{nk}\in\mathcal{R}$,
    set the following device:
    \begin{displaymath}
        \left.\left[
                \begin{split}
                    y^{k} &= y^{k-1}\hat{h}(y) \Omega_{0}(y) + 
                    y^{k-1}\hat{h}(y)^{2} \Omega_{1}(y) \\
                    &+ y^{k-1}\hat{h}(y)^{3} \Omega_{2}(y) +
                    \ldots +
                    y^{k-1}\hat{h}(y)^{i+1} \Omega_{i}(y) + \ldots
                \end{split}
            \right| y = h(t) \right]
    \end{displaymath}
    a simplification rewrites:
    \begin{displaymath}
        \left.\left[
            y = \hat{h}(y) \Omega_{0}(y) + 
            \hat{h}(y)^{2} \Omega_{1}(y) + \hat{h}(y)^{3} \Omega_{2}(y) +
            \ldots +
            \hat{h}(y)^{i+1} \Omega_{i}(y) + \ldots
            \right| y = h(t) \right]
    \end{displaymath}
    Here are our thoughts:
    \begin{itemize}
        \item it can be seen as an additional generalization of the last device,
            where some new functions are thrown in, in order to augment the
            combination including sets of coefficients lying on more rows, 
            each of them combined according a new introduced function $\Omega_{j}$,
            which are \emph{explicitly given}.  As before,
            you are interested to find one such function, say $\Omega_{0}$,
            and you can really do it since it is the same to solve a system
            with one equation in one unknown;
        \item it provides a ``factorization'' of function $A(t)$ with coefficients
            over $\mathcal{R}$'s $A$-sequence, respect function $\hat{h}$, 
            the compositional inverse of function $h$.  
            Recognizing $h(t)=tA(h(t))$ yield:
            \begin{displaymath}
                \left.\left[
                    A(y) =  \Omega_{0}(y) + 
                    \hat{h}(y)\,\Omega_{1}(y) + \hat{h}(y)^{2}\,\Omega_{2}(y) + \ldots +
                    \hat{h}(y)^{i}\,\Omega_{i}(y) + \ldots
                    \right| y = h(t) \right]
            \end{displaymath}
            This is quite interesting from the theoretical point of 
            view but can have a practical application
            when every term is in the polynomial ring: if this is the case,
            can apply the \emph{division theorem} among polynomial and 
            proceed to factor polynomial $A$ dividing it by polynomial $\hat{h}$,
            repeatedly.

            For the sake of clarity, \added{consider the following cases:}
            \begin{itemize}
            \item \replaced{let $\mathcal{P}$ be the}{consider} 
                Pascal array $\mathcal{P}$ \replaced{and recall the following facts:}{
                : recall that $\hat{h}(y)=\frac{y}{1+y}$ and $A(y)=1+y$}
            \begin{displaymath} 
                \added{
                \hat{h}_{\mathcal{P}}(y)=\frac{y}{1+y} \quad\quad A_{\mathcal{P}}(y)=1+y
                }
            \end{displaymath} 
            therefore, by \emph{division theorem}, 
            there exist polynomials $\Omega_{0}$ and \replaced{$\Delta_{0}$}{
                $\Omega_{1}$} such that:
            \begin{displaymath}
                \left.\left[
                    (1+y)^2 =  (1+y)\Omega_{0}(y) + y\,\replaced{\Delta_{0}}{
                \Omega_{1}}(y) \right| y = \replaced{h_{\mathcal{P}}}{h}(t) \right]
            \end{displaymath}
            dividing $(1+y)^2$ by $y$ yield \replaced{$\Delta_{0}$}{
                $\Omega_{1}$}$(y)=2+y$ and $(1+y)\Omega_{0}(y)=1$ \added{, 
                this define polynomial $\Omega_{0}$}.  
            \added{We need to 
            keep applying \emph{division theorem}, so there exist the following
            sequences of polynomials such that:}
            \begin{lenghtydisplaymath}
                \begin{split} 
                    &
                    \added{
                    \left.\left[
                        \frac{\Delta_{0}(y)}{\hat{h}_{\mathcal{P}}(y)} = 
                            \left(y+3, 2\right)\triangleq
                            \left(\Delta_{1}(y), (1+y)\Omega_{1}(y) \right)
                         \right| y = h_{\mathcal{P}}(t) \right]
                    }\\
                    &
                    \added{
                    \left.\left[
                        \frac{\Delta_{1}(y)}{\hat{h}_{\mathcal{P}}(y)} = 
                            \left(y+4, 3\right)\triangleq
                            \left(\Delta_{2}(y), (1+y)\Omega_{2}(y) \right)
                         \right| y = h_{\mathcal{P}}(t) \right]
                    }\\
                    &
                    \added{
                    \left.\left[
                        \frac{\Delta_{2}(y)}{\hat{h}_{\mathcal{P}}(y)} = 
                            \left(y+5, 4\right)\triangleq
                            \left(\Delta_{3}(y), (1+y)\Omega_{3}(y) \right)
                         \right| y = h_{\mathcal{P}}(t) \right]
                    }\\
                    &
                    \added{
                    \left.\left[
                        \frac{\Delta_{3}(y)}{\hat{h}_{\mathcal{P}}(y)} = 
                            \left(y+6, 5 \right)\triangleq
                            \left(\Delta_{4}(y), (1+y)\Omega_{4}(y) \right)
                         \right| y = h_{\mathcal{P}}(t) \right]
                    }\\
                    &\vdots
                \end{split} 
            \end{lenghtydisplaymath}
            \added{A pattern seems to emerge and can be captured with the 
            following rule in order to define polynomial $\Omega_{i}$:}
            \begin{displaymath} 
                \added{
                    \left.\left[
                        \Delta_{i-1}(y) \triangleq q_{i-1}(y) + r_{i-1}
                        \rightarrow (1+y)\,\Omega_{i}(y)=r_{i-1}
                         \right| y = h_{\mathcal{P}}(t) \right]
                }
            \end{displaymath} 
            \added{where each polynomial $q_{j}$ satisfies $q_{j}(0)=0$ and
            each $r_{j}\in\mathbb{N}$ is a remainder, with boundary initial 
            condition $\Delta_{-1}(y)=1$. Therefore it is possible to state
            a closed formula for polynomial $\Omega_{i}$:} 
            \begin{displaymath} 
                \added{\Omega_{i}(y)=\frac{1+i}{1+y}}
            \end{displaymath} 

            Putting it all together, the factorization of polynomial 
            \replaced{$A_{\mathcal{P}}$}{$A$} respect polynomial 
            $\replaced{\hat{h}_{\mathcal{P}}}{\hat{h}}$ is:
            \begin{displaymath}
                \replaced{
                    \left.\left[
                        A_{\mathcal{P}}(y) = \sum_{i \geq0}{\left(\frac{1+i}{1+y}\right)
                            \hat{h}_{\mathcal{P}}(y)^{i}} \right| y = h_{\mathcal{P}}(t) \right]
                }{
                    \left.\left[
                        A(y) =  \frac{1}{1+y} + \hat{h}(y)(2+y) \right| y = h(t) \right]
                }
            \end{displaymath}

            \item
            \added{for Catalan array $\mathcal{C}$ things are quite interesting,
            first of all recall the following facts:}
            \begin{displaymath} 
                \added{
                \hat{h}_{\mathcal{C}}(y)=y-y^2 \quad\quad 
                    A_{\mathcal{C}}(y)=\frac{1}{1-y}
                }
            \end{displaymath} 
            \added{therefore, by \emph{division theorem}, 
            there exist polynomials $\Omega_{0}$ and $\Delta_{0}$ such that:}
            \begin{displaymath}
                \added{
                \left.\left[
                    1 = (1-y)\Omega_{0}(y) + y(1-y)^{2}\,\Delta_{0}(y) 
                        \right| y = h_{\mathcal{C}}(t) \right]
                }
            \end{displaymath}
            \added{dividing $1$ by $y(1-y)^2$ yield $\Delta_{0}(y)=0$ 
            and $(1-y)\Omega_{0}(y)=1$, this define polynomial $\Omega_{0}$. 
            This means that ``polynomial'' $A_{\mathcal{C}}$ is already
            the factorization of itself, which is the same to say that
            there exists a \emph{unique} $A$-matrix for $\mathcal{C}$, pretty curious;}

            \item
            \added{for Motzkin array $\mathcal{M}$ things are quite interesting,
            first of all recall the following facts:}
            \begin{displaymath} 
                \added{
                \hat{h}_{\mathcal{M}}(y)=\frac{y}{1+y+y^2} \quad\quad 
                    A_{\mathcal{M}}(y)=1+y+y^2
                }
            \end{displaymath} 
            \added{therefore, by \emph{division theorem}, 
            there exist polynomials $\Omega_{0}$ and $\Delta_{0}$ such that:}
            \begin{displaymath}
                \added{
                \left.\left[
                    (1+y+y^2)^2 = (1+y+y^2)\Omega_{0}(y) + y\,\Delta_{0}(y) 
                        \right| y = h_{\mathcal{M}}(t) \right]
                }
            \end{displaymath}
            \added{dividing $(1+y+y^2)^2$ by $y$ yield $\Delta_{0}(y)=2+3y+2y^2+y^3$ 
            and $(1+y+y^2)\Omega_{0}(y)=1$, this define polynomial $\Omega_{0}$,
            which expanded as fps equals: }
            \begin{displaymath}
                \added{
                \left.\left[
                    \Omega_{0}(y) = 1 -y +y^{3} -y^{4} + y^{6} 
                        -y^{7} + y^{9} -y^{10} 
                        + y^{12} + \mathcal{O}\left(y^{13}\right)
                        \right| y = h_{\mathcal{M}}(t) \right]
                }
            \end{displaymath}
            \added{We need to 
            keep applying \emph{division theorem}, so there exist the following
            sequences of polynomials such that:}
            \begin{lenghtydisplaymath}
                \begin{split} 
                    &
                    \added{
                    \left.\left[
                        \frac{\Delta_{0}(y)}{\hat{h}_{\mathcal{M}}(y)} = 
                            \left(y^4 + 3y^3 + 6y^2 + 7y + 5, 2\right)\triangleq
                            \left(\Delta_{1}(y), (1+y+y^2)\Omega_{1}(y) \right)
                         \right| y = h_{\mathcal{M}}(t) \right]
                    }\\
                    &
                    \added{
                    \left.\left[
                        \frac{\Delta_{1}(y)}{\hat{h}_{\mathcal{M}}(y)} = 
                            \left(y^5 + 4y^4+10y^3+16y^2 + 18y + 12, 5\right)\triangleq
                            \left(\Delta_{2}(y), (1+y+y^2)\Omega_{2}(y) \right)
                         \right| y = h_{\mathcal{M}}(t) \right]
                    }\\
                    &
                    \added{
                    \left.\left[
                        \frac{\Delta_{2}(y)}{\hat{h}_{\mathcal{M}}(y)} = 
                            \left(y^6 + 5y^5 + 15y^4 + 30y^3 + 44y^2+46y+30, 
                                12\right)\triangleq
                            \left(\Delta_{3}(y), (1+y+y^2)\Omega_{3}(y) \right)
                         \right| y = h_{\mathcal{M}}(t) \right]
                    }\\
                    &
                    \added{
                    \left.\left[
                        \frac{\Delta_{3}(y)}{\hat{h}_{\mathcal{M}}(y)} = 
                            \left(y^7+6y^6+21y^5+50y^4+89y^3+120y^2+120y+76, 30
                                \right)\triangleq
                            \left(\Delta_{4}(y), (1+y+y^2)\Omega_{4}(y) \right)
                         \right| y = h_{\mathcal{M}}(t) \right]
                    }\\
                    &\vdots
                \end{split} 
            \end{lenghtydisplaymath}
            \added{A pattern seems to emerge and can be captured with the 
            following rule in order to define polynomial $\Omega_{i}$:}
            \begin{displaymath} 
                \added{
                    \left.\left[
                        \Delta_{i-1}(y) \triangleq q_{i-1}(y) + r_{i-1}
                        \rightarrow (1+y+y^2)\,\Omega_{i}(y)=r_{i-1}
                         \right| y = h_{\mathcal{M}}(t) \right]
                }
            \end{displaymath} 
            \added{where each polynomial $q_{j}$ satisfies $q_{j}(0)=0$ and
            each $r_{j}\in\mathbb{N}$ is a remainder, with boundary initial 
            condition $\Delta_{-1}(y)=1$.}

            \added{It is quite interesting that, as the case for array $\mathcal{P}$,
            the sequence $\lbrace r_{j} \rbrace_{j\in\mathbb{N}}$ of remainders
            is exactly the sequence of coefficients of the function defining
            the second column of array $\mathcal{M}$, namely function 
            $d_{\mathcal{M}}$ times function $h_{\mathcal{M}}$, shifted by \emph{one}
            position. Putting it all together, the factorization of polynomial 
            $A_{\mathcal{M}}$ respect polynomial $\hat{h}_{\mathcal{M}}$ is:}
            \begin{displaymath}
                \added{
                    \left.\left[
                        A_{\mathcal{M}}(y) = \sum_{i \geq0}{
                            \left(\frac{[t^{1+i}]d_{\mathcal{M}}(t)h_{\mathcal{M}}(t)}
                                {1+y+y^2}\right)
                            \hat{h}_{\mathcal{M}}(y)^{i}} 
                            \right| y = h_{\mathcal{M}}(t) \right]
                }
            \end{displaymath}

            \item if terms are not in a polynomial ring, we've difficulty to show a
            factorization: \replaced{for example Delannoy array $\mathcal{D}$ is}
            {both Catalan array $\mathcal{C}$ both Delannoy array
            $\mathcal{D}$ are} affected by this difficulty.

            \end{itemize}
            
        \item looking at the formulation under study, we observe that functions
            $\Omega_{0}, \Omega_{1}, \Omega_{2}, \ldots$ are exactly the same
            as those introduced by Merlini et al., therefore we've expressed
            the concept of $A$-matrix from a different point of view. A problem
            is still open: what if we would like to find all such functions? A reply
            to this question seems interesting but we've no idea how to satisfy it.
            The major difficulty can be spotted looking at the device as a system:
            there's \emph{one} equation in possibly $k$ unknowns, no
            idea about the shape of the remaining $k-1$ equations.

            Have a little check about Pascal array $\mathcal{P}$ again:
            let $d_{nk}\in\mathcal{P}$, from the point above we've, firstly,
            $\Omega_{0}(y)=\frac{1}{1+y}$, which says to sum elements
            \added{lying} on row $n-1$ using alternating sings
            \replaced{; then add the doubled sum of
            elements lying on row $n-2$ using alternating signs; 
            then add the tripled sum of elements lying on row $n-3$ 
            using alternating signs; and so on \ldots}
            { and, secondly, $\Omega_{1}(y)=2+y$, 
            which says to double the ``first'' element and sum to the ``second'' element
            on row $n-2$}, all respect column index $k$. 
            
            Element $d_{7,4}$, chosen at random, is the combination 
            \replaced{$(d_{6,3}-d_{6,4}+d_{6,5}-d_{6,6})+
                2(d_{5,3}-d_{5,4}+d_{5,5}) + 3(d_{4,3}-d_{4,4}) + 4d_{4,4}$, 
                instantiating $35 = (20-15+6-1)+2(10-5+1)+3(4-1)+4\cdot1$
                }{
            $d_{6,3}-d_{6,4}+d_{6,5}-d_{6,6}+2d_{5,3}+d_{5,4}$, instantiating
            $35 = 20-15+6-1+2\cdot10+5$
            } which holds.

            \deleted[remark=boring and tedious the combination for $d_{8,1}$]{
                Element $d_{8,1}$, chosen at random, is the combination
                $d_{7,0}-d_{7,1}+d_{7,2}-d_{7,3}+d_{7,4}-d_{7,5}+d_{7,6}-d_{7,7}
                    +2d_{7,0}+d_{7,1}$, instantiating 
                    $8 = 1-7+21-35+35-21+7-1+2\cdot1+6$ which holds.}
            

            \added{On the other hand, let $d_{6,2}\in\mathcal{M}$ be the
            combination $(d_{5,1}-d_{5,2}+d_{5,4}-d_{5,5})
                +2(d_{4,1}-d_{4,2}+d_{4,4})
                +5(d_{3,1}-d_{3,2})
                +12(d_{2,1} -d_{2,2})
                +30\,d_{1,1}$, instantiating: 
                $69=(30-25+5-1)
                +2(12-9+1)
                +5(5-3)
                +12(2 -1)
                +30\cdot1$, which holds.}


    \end{itemize}
    


    \section{Implementation}
    In the rest of this document we report and comment some figures
    about colourings of \emph{Riordan arrays}: we consider standard triangles
    and their inverses, in the majority of case the congruence partitioning
    is used.

    Mathematically, a function $colouring$ has been implemented: let $\mathcal{R}$ be
    a Riordan array and $d_{nk} \in \mathcal{R}$ a generic element, moreover
    define a set of $k$ colours $\lbrace c_0, \ldots, c_{k-1} \rbrace$, so
    the function has the following type:
    \begin{displaymath}
        colouring : \mathbb{N} \times\mathbb{N} \rightarrow 
            \lbrace c_0, \ldots, c_{k-1} \rbrace
    \end{displaymath}

    The following implementations are available in the Python package:
    \begin{itemize}
        \item choose a module $p$ (in most cases a prime although) and
            colour $\mathcal{R}$ associating to each remainder class 
            $r \in \lbrace[0],\ldots,[p-1]\rbrace$
            a different colour $c_r$:
            \begin{displaymath}
                colouring_{p}(n,k) = c_{r} \leftrightarrow d_{nk} \equiv_{p} r
            \end{displaymath}
        \item choose a module $p$ (in most cases a prime although) and
            \emph{bi}-colour $\mathcal{R}$ with $c_0$ if $d_{nk}$ 
            is a multiple of $p$, otherwise use a colour $c_1$:
            \begin{displaymath}
                colouring_{p}(n,k) = c_{0} \leftrightarrow p | d_{nk}
            \end{displaymath}
        \item a less used one, \emph{bi}-colour $\mathcal{R}$ with $c_0$ 
            if $d_{nk}$ is a prime, otherwise use a colour $c_1$:
            \begin{displaymath}
                colouring(n,k) = c_{0} \leftrightarrow \not 
                    \exists p\in\lbrace 2,\ldots,d_{nk}-1\rbrace.p|d_{nk} 
            \end{displaymath}
    \end{itemize}

    \section{Pascal}

    \subsection{Some modular proofs}
    
    In this section we present some proofs about Pascal array and its
    inverse, taken modulo some prime $p$. Colouring with different
    colours elements belonging to different remainder classes, we show
    formally that for $p$ even, ie. $p=2$, elements in the same
    position get the same colour (hence both triangle are coloured the
    same way, ignoring signs for elements in the inverse array), while
    for $p$ odd there is not such a simple correspondence and we
    attempt to observe some repeating pattern of mapping between
    elements.

    Let $\mathcal{P}$ be the Riordan array for the Pascal triangle,
    defined as:
    \begin{displaymath} 
        \mathcal{P} = \left(\frac{1}{1-t}, \frac{t}{1-t}  \right)
    \end{displaymath} 
    and let $\mathcal{P}^{-1}$ be its inverse Riordan array:
    \begin{displaymath} 
        \mathcal{P}^{-1} = \left(\frac{1}{1+t}, \frac{t}{1+t}  \right)
    \end{displaymath} 
    
    Let $d_{nk}$ and $\hat{d}_{nk}$ be the generic element of Pascal
    array and of its inverse, respectively. Since both arrays are
    Riordan, by definition:
    \begin{displaymath}
        \begin{split}
            d_{nk} &= [t^n]\frac{1}{1-t}\left(\frac{t}{1-t}\right)^k = [t^{n-k}](1-t)^{-(k+1)} \\
                &= {{-(k+1)} \choose {n-k}}(-1)^{n-k} = {{k+1 +n-k -1} \choose {n-k}} = {{n} \choose {n-k}} \\
        \end{split}
    \end{displaymath}
    and for the inverse:
    \begin{displaymath}
      \begin{split}
        \hat{d}_{nk} &= [t^n]\frac{1}{1+t}\left(\frac{t}{1+t}\right)^k = [t^{n-k}](1+t)^{-(k+1)} = 
        {{-(k+1)} \choose {n-k}} \\
        &= {{k+1 +n-k -1} \choose {n-k}} (-1)^{n-k} = {{n} \choose {n-k}} (-1)^{n-k}\\
      \end{split}
    \end{displaymath}
    Hence, equating binomial coefficients yields:
    \begin{displaymath}
      [t^n]\frac{1}{1-t}\left(\frac{t}{1-t}\right)^k = (-1)^{k-n}[t^n]\frac{1}{1+t}\left(\frac{t}{1+t}\right)^k 
    \end{displaymath}
    Choose a prime $p$ and take the modulo of both members:
    \begin{displaymath}
      [t^n]\frac{1}{1-t}\left(\frac{t}{1-t}\right)^k \equiv_{p} (-1)^{k-n}[t^n]\frac{1}{1+t}\left(\frac{t}{1+t}\right)^k 
    \end{displaymath}

    From now on we have to reason according modular arithmetic, hence
    multiply by a term $a$ both member of equations in order to
    simplify requests to show the existence of multiplicative inverse
    modulo $p$ of $a$, denoted by: $$a^{-1}\mod p$$

    First of all, observe that $-1 \equiv_{p} p-1$ and since $p$ is a
    prime by hp, it follows that $(p, p-1)=1$ (this result holds in
    general, not just for $p$ prime), which proofs the existence of
    both $-1$ and $p-1$ inverses, denoted by $(-1)^{-1}\mod p$ and
    $(p-1)^{-1}\mod p$ respectively.

    In order to find $(p-1)^{-1}\mod p$ we have to satisfy the
    congruence equation $(p-1) * (p-1)^{-1} \equiv_{p} 1$. Choose
    $(p-1)^{-1}\mod p = p-1$ and verify
    $(p-1) * (p-1) \equiv_{p} p^2 -2p +1 \equiv_{p} 1$ as required.

    Another useful observation concerns raising to negative powers,
    let $k \geq 0$:
    \begin{displaymath}
        (-1)^{-k} \equiv_{p} \left((-1)^{-1}\right)^{k} \equiv_{p} (p-1)^k
    \end{displaymath}
    and since $-1 \equiv_{p} p-1$ it follows that
    $(-1)^{-k} \equiv_{p} (-1)^k$, surprising to me.
    
    Now we can use previous observation to the main modular equation:
    \begin{displaymath}
        \begin{split}
            [t^n]\frac{1}{1-t}\left(\frac{t}{1-t}\right)^k 
                &\equiv_{p} (-1)^{k-n}[t^n]\frac{1}{1+t}\left(\frac{t}{1+t}\right)^k \\
                &\equiv_{p} (-1)^{k+n}[t^n]\frac{1}{1+t}\left(\frac{t}{1+t}\right)^k \\
                &\equiv_{p} (p-1)^{k+n}[t^n]\frac{1}{1+t}\left(\frac{t}{1+t}\right)^k \\
        \end{split}
    \end{displaymath}
    Hence, multiplying by $(p-1)^{-1}\mod p$ both members $k+n$ times:
    \begin{displaymath}
        (p-1)^{k+n}[t^n]\frac{1}{1-t}\left(\frac{t}{1-t}\right)^k \equiv_{p} [t^n]\frac{1}{1+t}\left(\frac{t}{1+t}\right)^k 
    \end{displaymath}
    which is the same as:
    \begin{displaymath}
        (-1)^{k+n}[t^n]\frac{1}{1-t}\left(\frac{t}{1-t}\right)^k \equiv_{p} [t^n]\frac{1}{1+t}\left(\frac{t}{1+t}\right)^k 
    \end{displaymath}
    and relating generic elements $d_{nk}$ with $\hat{d}_{nk}$:
    \begin{displaymath}
        (p-1)^{k+n}d_{nk}\equiv_{p}(-1)^{k+n}d_{nk} \equiv_{p} \hat{d}_{nk}
    \end{displaymath}

    \subsubsection{$p=2$}
    The case for $p$ even prime produce the colouring reported in
    REGENERATE AND PUT HERE THE RIGHT REFERENCE TO PASCAL: ignoring
    signs in the inverse array, we got the same colouring.  This is
    justified using the previous argument with $p=2$, for any choice
    of $n, k \geq 0$:
    \begin{displaymath} 
        d_{nk} \equiv_{2} \hat{d}_{nk} 
    \end{displaymath} 

    \subsubsection{$p=3$}
    Here there's a more interesting pattern to study, and in general,
    for any odd prime $p$, colourings of standard and inverse arrays
    mismatch. In this section we tackle the case for $p=3$,
    instantiating the modular equation:
    \begin{displaymath}
      2^{k+n}d_{nk}\equiv_{3}(-1)^{k+n}d_{nk} \equiv_{3} \hat{d}_{nk}
    \end{displaymath}
    For the sake of clarity, consider row 4th of both triangles:
    \begin{itemize}
    \item $\mathcal{P}[3,:] = (1 \quad 3 \quad 3 \quad 1) \equiv_{3}(1 \quad 0 \quad 0 \quad 1)$
    \item $\mathcal{P}^{-1}[3,:] = (-1 \quad 3 \quad -3 \quad 1) \equiv_{3}(2 \quad 0 \quad 0 \quad 1)$
    \end{itemize}
    Hence element $d_{30}$ gets a color $c$ while $\hat{d}_{30}$ gets
    a color $c'$ different from $c$.

    No general mapping among this relationship appears, so we
    carefully study two coloured triangles.  First fix a row which
    will be our reference row, choose index $3^4$. Repeatedly, move up
    one by one, and for each considered row move on the right over
    columns, here a modular equivalence going up one row:
    \begin{displaymath}
        \begin{split}
            d_{3^4 -1,0} &\equiv_{3} \hat{d}_{3^4 -1,0} \\
            d_{3^4 -1,1} &\equiv_{3} \hat{d}_{3^4 -2,0} \\
            d_{3^4 -1,2} &\equiv_{3} \hat{d}_{3^4 -3,0} \\
            d_{3^4 -1,3} &\equiv_{3} \hat{d}_{3^4 -4,0} \\
            &\vdots
        \end{split}
    \end{displaymath}
    next, a modular equivalence going up two rows:
    \begin{displaymath}
        \begin{split}
            d_{3^4 -2,0} &\equiv_{3} \hat{d}_{3^4 -1,1} \\
            d_{3^4 -2,1} &\equiv_{3} \hat{d}_{3^4 -2,1} \\
            d_{3^4 -2,2} &\equiv_{3} \hat{d}_{3^4 -3,1} \\
            d_{3^4 -2,3} &\equiv_{3} \hat{d}_{3^4 -4,1} \\
            &\vdots
        \end{split}
    \end{displaymath}
    next, a modular equivalence going up three rows:
    \begin{displaymath}
        \begin{split}
            d_{3^4 -3,0} &\equiv_{3} \hat{d}_{3^4 -1,2} \\
            d_{3^4 -3,1} &\equiv_{3} \hat{d}_{3^4 -2,2} \\
            d_{3^4 -3,2} &\equiv_{3} \hat{d}_{3^4 -3,2} \\
            d_{3^4 -3,3} &\equiv_{3} \hat{d}_{3^4 -4,2} \\
            &\vdots
        \end{split}
    \end{displaymath}
    Let introduce variable $b$, running over rows, and $a$, running
    over columns; a pattern appears, here it is:
    \begin{displaymath}
            d_{3^4 +b,a} \equiv_{3} \hat{d}_{3^4 -1-a,-1-b} 
    \end{displaymath}

    Let's say, assume the colouring for $\mathcal{P}^{-1}$ triangle is
    given, the colouring for row $26$ of $\mathcal{P}$ is desired. It
    is necessary to find $b$: by $3^4 +b=26$ get $b=-55$, so the
    required row satisfy the following modular equivalence:
    \begin{displaymath}
            d_{26,a} \equiv_{3} \hat{d}_{80-a,54} 
    \end{displaymath}
    This is pretty curious since in order to colour a row in triangle
    $\mathcal{P}$, from left to right since for proper arrays
    $a \geq 0$, column's colouring in triangle $\mathcal{P}^{-1}$ is
    used, from bottom to top\footnote{Some pictures highlighting the
      interested rows and columns should be very helpful}.
    \\\\
    A question is still open: why do we choose row $3^4$ as reference
    row?

    It is useful to recall a theorem due to Fine:
    \begin{theorem}
      A necessary and sufficient condition for a binomial coefficient
      ${{n} \choose {m}}$ to be divisible by a prime $p$ is that $n$
      be a power of $p$.
    \end{theorem}
    Consider the colouring for triangle $\mathcal{P}$, we can use the
    given theorem to point out ``interesting'' rows, namely those rows
    affected by the theorem, they correspond to powers
    $3^1, 3^2, 3^3, 3^4, \ldots$, each one of them can be easily
    recognized since dots lying on it have all the same colour. In the
    triangle $127$ former rows are drawn and in order to have ``more
    space'' to find a modular relationship between $d_{nk}$ and
    $\hat{d}_{nk}$ we choose as \emph{reference} row the one with
    index $3^4$.  From here we start moving backwards by rows toward
    the root: observe that the entire row $3^4 -1$, containing
    $3^4 -1$ remainders, of triangle $\mathcal{P}$ is the first
    segment of the first column of $\mathcal{P}^{-1}$, in other words
    $d_{3^4 -1,a} \equiv_{3} \hat{d}_{3^4 -1 -a, 0}$ for
    $a \in \lbrace 0, \ldots, 3^4 -1\rbrace$.

    It seems that coefficient $d_{3^4-1,0}$ acts as a pivot on which
    the triangle ``flips'': the root moves toward the reader while the
    bottom edge moves toward opposite the reader. This rigid motion is
    captured by the following modular relationships among three
    important points:
    \begin{displaymath}
        \begin{split}
            d_{3^4 -1,0} &\equiv_{3} \hat{d}_{3^4 -1,0} \\
            d_{3^4 -1,3^4 -1} &\equiv_{3} \hat{d}_{0,0} \\
            d_{3^4 -3^3,3^3-1} &\equiv_{3} \hat{d}_{3^4 -3^3,3^3-1} \\
        \end{split}
    \end{displaymath}

    \subsection{Sierpinski structure}

    In this section we show that in a Pascal array $\mathcal{P}$ it is
    possible to recognize a structure as Sierpinski observed using
    fractals. More precisely, we show that, chosen a prime $p$ and a
    height $n$, the upper triangle that starts at root and extends
    downward for $p^n$ rows, denoted by $\mathcal{P}_n$, repeats
    itself three times in a bigger triangle that extends from the root
    downward for $2p^{n}$ rows, surrounding an upside-down triangle of
    coefficients, say $c_{nk}$ is one of those, such that are divisible
    by $p$ all, formally $c_{nk} \equiv_p 0$. Note that for even prime
    $p$, triangle $\mathcal{P}_n$ repeats itself $p+1$ times in
    $\mathcal{P}_{n+1}$, exactly as it is.
    
    On the other hand, for an odd prime $p$ the structure loses
    symmetry. In this case triangle $\mathcal{P}_n$ repeats itself in
    $\mathcal{P}_{n+1}$ somewhere, without a plain regularity due to
    modulo $p$, ie. other coloured triangles appears in
    $\mathcal{P}_{n+1}$.  However if we study the repetition up to row
    $2p^n$ the proof still hold, while in general we can say that
    maximal triangles of coefficients multiples of $p$, appear with regularity
    in $\mathcal{P}_{n+1}$ a number of times equals to:
    \begin{displaymath}
        \frac{(p-1)p}{2}
    \end{displaymath}
    in other words, considering triangles $\mathcal{P}_{n}$ and
    $\mathcal{P}_{n+1}$, there are $\frac{(p-1)p}{2}$ upside-down
    maximal triangles, with all coefficients multiple of $p$, from row $p^n$
    to row $p^{n+1}-1$; this result will be prove at the end of this 
    section.

    \begin{proof}
      Let $\mathcal{P}_n$ be the triangle that starts at the root and
      extends downward $p^n$ rows, hence a row index $r$ for
      $\mathcal{P}_n$ satisfies
      $r \in \lbrace 0, \ldots, p^n -1 \rbrace$.
        
      Now consider a bigger triangle $\mathcal{P}_n^\prime$ that
      starts at the root and extends downward $2p^n$ rows, it is
      requested to prove that coefficients in \emph{equivalent
        positions} in the bottom left and bottom right triangles are
      congruent, modulo $p$, to the coefficient in equivalent position
      in $\mathcal{P}_n$. In order to formalize the concept of
      \emph{equivalent positions} think as follow: let
      $d_{rc}\in\mathcal{P}_n$, since $\mathcal{P}_{n}$ has $p^n$ rows
      and on the vary last row (ie, the one with index $p^n-1$) lay
      $p^n$ coefficients (ie, there are $p^n$ columns), the
      coefficient at \emph{equivalent position} in the bottom left
      triangle of $\mathcal{P}_{n}^\prime$ is denoted by
      $d_{p^n+r, c}^{\swarrow}$; on the other hand, the coefficient at
      \emph{equivalent position} in the bottom right triangle of
      $\mathcal{P}_{n}^\prime$ is denoted by
      $d_{p^n+r, p^n+c}^{\searrow}$.  Formal settings described, we've
      to prove:
      \begin{displaymath}
        d_{rc} \equiv_p d_{p^n+r,c}^{\swarrow} \equiv_p d_{p^n+r,p^n+c}^{\searrow} 
      \end{displaymath}
      or, in other words:
      \begin{displaymath}
        {{r} \choose {c}} \equiv_p {{p^n+r} \choose {c}} \equiv_p {{p^n+r} \choose {p^n+c}} 
      \end{displaymath}

      In order to prove such congruences we'll use Lucas theorem:
      first of all, observe that $c \leq r$ since $\mathcal{P}$ is a
      triangle, therefore $c \in \lbrace 0, \ldots, p^n -1 \rbrace$,
      as $r$ satisfies.  By basis representation theorem, there exists
      sequences $\lbrace r_i\rbrace$ and $\lbrace c_i\rbrace$, for
      $i \in \lbrace 0, \ldots, p^n -1 \rbrace$, with $r_i,c_i < p$,
      such that:
      \begin{displaymath}
        \begin{split}
          r &= r_0 + r_1 p + r_2 p^2 + \ldots + r_{n-1}p^{n-1} \\
          c &= c_0 + c_1 p + c_2 p^2 + \ldots + c_{n-1}p^{n-1} \\
        \end{split}
      \end{displaymath}
      Settings for Lucas theorem are ready, hence apply it:
      \begin{displaymath}
        \begin{split}
          {{p^n+r} \choose {c}} &\equiv_{p} {{r_0} \choose {c_0}} {{r_1} \choose {c_1}}{{r_2} \choose {c_2}} \ldots 
          {{r_{n-1}} \choose {c_{n-1}}}{{1} \choose {0}} \equiv_{p} {{r} \choose {c}}\\
          {{p^n+r} \choose {p^n+c}} &\equiv_{p} {{r_0} \choose {c_0}} {{r_1} \choose {c_1}}{{r_2} \choose {c_2}} \ldots 
          {{r_{n-1}} \choose {c_{n-1}}}{{1} \choose {1}} \equiv_{p} {{r} \choose {c}}\\
        \end{split}
      \end{displaymath}
      congruences holds, therefore coefficients located at
      \emph{equivalent positions} belong to the same remainder class,
      modulo $p$, as required.
      \\\\
      For the second part of the statement, we've to show that in
      $\mathcal{P}_{n}^\prime$ an upside-down triangle of
      coefficients, each one of them can by divided by $p$, is
      surrounded by the three ``congruent'' triangles discussed in the
      first part of this proof.  Observe that the very first
      coefficient $d_{p^n, 0}$ and very last $d_{p^n, p^n}$ of row
      with index $p^n$ are congruent to the unit, modulo $p$:
      \begin{displaymath}
        {{p^n} \choose {0}} \equiv_{p}{{p^n} \choose {p^n}} \equiv_{p} 1
      \end{displaymath}
      while $p$ divides every coefficient between them, let
      $c\in\lbrace1,\ldots, p^n-1 \rbrace$:
      \begin{displaymath}
        {{p^n} \choose {c}} \equiv_{p} {{0} \choose {c_0}} {{0} \choose {c_1}}{{0} \choose {c_2}} \ldots 
        {{0} \choose {c_{n-1}}}{{1} \choose {0}} \equiv_{p} 0
      \end{displaymath}
      By the recurrence rule $d_{n+1, k+1} = d_{n, k} + d_{n, k+1}$
      characterizing $\mathcal{P}$, observe that:
      \begin{displaymath}
        \begin{split}
          d_{p^n+1, 1} &\equiv_{p} d_{p^n, 0} + d_{p^n, 1}\equiv_{p} 1 \\
          d_{p^n+1, p^n} &\equiv_{p} d_{p^n, p^n-1} + d_{p^n, p^n}\equiv_{p} 1 \\
          d_{p^n+1, i} &\equiv_{p} d_{p^n, i-1} + d_{p^n, i}\equiv_{p} 0 \quad \forall i \in \lbrace 2, \ldots, p^n -1\rbrace \\
        \end{split}
      \end{displaymath}
      therefore row $p^n + 1$ has one coefficient multiple of $p$ less
      than row $p^n$, and since in $p^n$ there are $p^n-2$ such
      coefficients, after $p^n-2$ rows there are no such coefficients
      at all, such a row has index $2(p^n -1)+1$ ($1$ more because
      indexes are $0$-based). Formally, for any column index $c$:
      \begin{displaymath}
        \begin{split}
          {{2p^n - 1} \choose {c}} &\equiv_{p} {{p^n +(p^n- 1)} \choose {c}} \\
          &\equiv_{p} {{p-1} \choose {c_0}} {{p-1} \choose {c_1}}{{p-1} \choose {c_2}} \ldots 
          {{p-1} \choose {c_{n-1}}}{{1} \choose {0}} \\
          &\not\equiv_{p} 0
        \end{split}
      \end{displaymath}
      The last step holds by representation of $c$:
      $c_i \in \lbrace 0, \ldots, p-1 \rbrace$, for any $i$.

      The latter argument can be applied to every row with index of
      the form $p^k -1$, for some $k\geq n$:
      \begin{displaymath}
        \begin{split}
          {{p^k-1} \choose {c}} &\equiv_{p} {{p-1} \choose {c_0}} {{p-1} \choose {c_1}} \ldots 
          {{p-1} \choose {c_{n-1}}}{{p-1} \choose {0}}\ldots{{p-1} \choose {c_{k-1}=0}} \not\equiv_{p} 0
        \end{split}
      \end{displaymath}

      % the following derivation is simply a proof of coefficient extraction
      % using the definition of Riordan array for Pascal triangle, redundant.
      % Recall $\mathcal{P}$ is defined as the Riordan array :
      % \begin{displaymath}
      %   \mathcal{P} = \left(\frac{1}{1-t}, \frac{t}{1-t}  \right)
      % \end{displaymath}
      % hence the following derivation holds:
      % \begin{displaymath}
      %   \begin{split}
      %     {{p^n+r} \choose {c}} &\equiv_p [t^{p^n +r}]\frac{1}{1-t} \left(\frac{t}{1-t}\right)^c \\
      %     &\equiv_p [t^{p^n +r-c}](1-t)^{-(c+1)} \\
      %     &\equiv_p [t^{p^n +r-c}]\mathcal{G}\left\lbrace {{-(c+1)} \choose {k}}(-1)^k \right\rbrace_{k\in\mathbb{N}} \\
      %     &\equiv_p  {{-(c+1)} \choose {p^n +r-c}}(-1)^{p^n +r-c}  \\
      %     &\equiv_p  {{ p^n +r} \choose {p^n +r-c}} \left((-1)^{p^n +r-c}\right)^2  \\
      %     &\equiv_p  {{ p^n +r} \choose {c}}  \\
      %   \end{split}
      % \end{displaymath}

    \end{proof}

    We present a modular characterization under the theory of Riordan arrays, using the
    congruence modulo a prime $p$. Choose $n\in\mathbb{N}$ and let $\mathcal{P}_n$ denote the
    same portion of $\mathcal{P}$ as in the preceding proof:
      \begin{displaymath}
          \begin{split}
                {{r} \choose {c}} &\equiv_p {{p^n+r} \choose {c}} \\
                {{r} \choose {c}}t^r &\equiv_p {{p^n+r} \choose {c}}t^r \\
                \sum_{r\geq 0}{{{r} \choose {c}}t^r} &\equiv_p \sum_{r\geq 0}{{{p^n+r} \choose {c}}t^r} \\
                d(t)h(t)^{c} &\equiv_p \sum_{k\geq p^n}{{{k} \choose {c}}t^{k-p^n}} \\
                d(t)h(t)^{c} &\equiv_p t^{-p^n}\sum_{k\geq p^n}{{{k} \choose {c}}t^{k}} \\
                d(t)h(t)^{c} &\equiv_p t^{-p^n}\left(
                    \sum_{k\geq c}{{{k} \choose {c}}t^{k}}-\sum_{k=c}^{p^n -1}{{{k} \choose {c}}t^{k}}\right) \\
                d(t)h(t)^{c} &\equiv_p t^{-p^n}\left(
                    \sum_{k\geq 0}{{{k} \choose {c}}t^{k}}-\sum_{k=c}^{p^n -1}{{{k} \choose {c}}t^{k}}\right) \\
                d(t)h(t)^{c} &\equiv_p t^{-p^n}\left(d(t)h(t)^{c} -\sum_{k=c}^{p^n -1}{{{k} \choose {c}}t^{k}}\right) \\
          \end{split}
      \end{displaymath}
    Now assume $c \geq p^n$ in order to make the sum vanish:
      \begin{displaymath}
          \begin{split}
                d(t)h(t)^{c} &\equiv_p t^{-p^n} d(t)h(t)^{c} \\
                d(t)h(t)^{c} &\equiv_p d(t)h(t)^{c-p^n} (1-t)^{-p^n} \\
          \end{split}
      \end{displaymath}
    Since in general the inverse $\left((1-t)^{-p^n}\right)^{-1}\mod p$ is not $(1-t)^{p^n}$
    (we should prove it), let us proceed with algebraic manipulation:
      \begin{displaymath}
          \begin{split}
                d(t)h(t)^{c} &\equiv_p d(t)h(t)^{c-p^n}\left( (1-t)^{p^n}\right)^{-1} \\
                d(t)h(t)^{c} &\equiv_p d(t)h(t)^{c-p^n}\left(\sum_{k=0}^{p^n}{{{p^n} \choose {k}}(-t)^k } \right)^{-1}\\
                d(t)h(t)^{c} &\equiv_p d(t)h(t)^{c-p^n}\left(
                    1 + \sum_{k=1}^{p^n -1}{{{p^n} \choose {k}}(-t)^k +(-t)^{p^n} }\right)^{-1} \\
          \end{split}
      \end{displaymath}
    By Lucas theorem the inner sum vanish, since $k\in\lbrace 1, \ldots, p^n -1 \rbrace$:
      \begin{displaymath}
        \begin{split}
          {{p^n} \choose {k}} &\equiv_{p} {{0} \choose {k_0}} {{0} \choose {k_1}} \ldots 
          {{0} \choose {k_{n-1}}}{{1} \choose {0}}\equiv_{p} 0 
        \end{split}
      \end{displaymath}
    Therefore:
      \begin{displaymath}
          \begin{split}
                d(t)h(t)^{c} &\equiv_p d(t)h(t)^{c-p^n}\left(1 + (-t)^{p^n}\right)^{-1} \\
          \end{split}
      \end{displaymath}
    And assuming $p$ odd:
      \begin{displaymath}
          \begin{split}
                d(t)h(t)^{c} &\equiv_p \frac{d(t)h(t)^{c-p^n}}{1 - t^{p^n}} \\
          \end{split}
      \end{displaymath}

    Let us finish this section with the proof of an observation about
    maximal upside down triangle of coefficients, each one of them 
    multiple of $p$.

    \begin{lemma}
        Let $\mathcal{P}_n$ be a chunk of $\mathcal{P}$ and let $j\in
        \lbrace 1, \ldots, p-1 \rbrace$. Between row index $j p^n$ and
        row index $(j+1)p^n -1$, there are $j$ maximal upside down triangles
        such that if a coefficient $d_{nk}$ belongs to one of them, then 
        $d_{nk} \equiv_{p} 0$.
    \end{lemma}

    \begin{proof}
        By ``bounded'' induction on $j$.
        \begin{itemize}
            \item base $j=1$: this is the case seen before in the proof of
                Sierpinski structure were it had been proved that a triangle
                of coefficients, each coefficient multiple of $p$, is surrounded
                by three copies of the same triangle, considering rows from index 
                $p^n$ up to $2 p^n -1$, as this case requires;
            \item induction hp: assume that the statement is true for $j = p-2$, namely
                between row index $(p-2) p^n$ and row index $(p-1)p^n -1$, 
                there are $p-2$ maximal upside down triangles
                such that if a coefficient $d_{nk}$ belongs to one of them, then 
                $d_{nk} \equiv_{p} 0$; 
            \item induction step: show the statement holds for $j=p-1$. 
                We approach this case by a reduction to absurd, therefore assume that
                between row index $(p-1) p^n$ and row index $p^{n+1} -1$, 
                there are \emph{at most} $p-2$ maximal upside down triangles
                such that if a coefficient $d_{nk}$ belongs to one of them, then 
                $d_{nk} \equiv_{p} 0$. In other words, at least one triangle, call it $\mathcal{T}$,
                    is missing: there exists a coefficient
                    $\tilde{d}_{nk}\in\mathcal{T}$ such that $\tilde{d}_{nk}\not\equiv_{p}0$, while all 
                    other coefficient $d_{nk}\in\mathcal{T}$ satisfies $d_{nk} \equiv_{p}0$.
                    Proceed by cases on parity of $j$:
                \begin{description}
                    \item[$j=2k+1$ for some $k$] Without loss of generality, suppose $\mathcal{T}$ is the one in the 
                    very middle, due to symmetry of $\mathcal{P}$ (the cases where it is on the left or on the right are less interesting) and
                    suppose that $\tilde{d}_{(j+1) p^n -2, (k+1)p^n -1}\not\equiv_{p}0$, the coefficient in the very bottom corner.
                    But this is impossible because $d_{nk} = d_{n-1,k-1} + d_{n-1, k}$ if $d_{nk}\in \mathcal{P}$:
                    \begin{displaymath}
                    0\not\equiv_{p}\tilde{d}_{(j+1) p^n -2, (k+1)p^n -1} \equiv_{p} 
                        \tilde{d}_{(j+1) p^n -1, (k+1)p^n -1} + \tilde{d}_{(j+1) p^n -1, (k+1)p^n }\equiv_{p}0
                    \end{displaymath}

                    \item[$j=2k$ for some $k$] Without loss of generality, suppose  $\mathcal{T}$ is the one on the very left. 
                    Choose $r \in\lbrace 0,\ldots,p^n-2\rbrace$ and $c \in\lbrace r+1,\ldots,p^n-1\rbrace$,
                    suppose that $\tilde{d}_{(j+1) p^n +r, c}\not\equiv_{p}0$. By symmetry of $\mathcal{P}$, we get another contradiction: 
                    \begin{displaymath}
                        0\not\equiv_{p}\tilde{d}_{(j+1) p^n +r, c} \equiv_{p} \tilde{d}_{(j+1) p^n +r, (j+1) p^n +r-c}\equiv_{p}0
                    \end{displaymath}
                \end{description}
        \end{itemize}
    \end{proof}
    

    \begin{theorem}
        In two adjacent chunks of $\mathcal{P}$, denote them by $\mathcal{P}_n$
        and $\mathcal{P}_{n+1}$ respectively, the
        number of upside down maximal triangles of coefficients $d_{nk}$, with
        $d_{nk} \equiv_p 0$, equals:
        \begin{displaymath}
            \frac{(p-1)p}{2}
        \end{displaymath}
    \end{theorem}

    \begin{proof}
        Choose any $n\in\mathbb{N}$ and let $\mathcal{P}_n$ and $\mathcal{P}_{n+1}$
        be the two chunk of $\mathcal{P}$ of interest. Let $j\in\lbrace 1, \ldots, p-1 \rbrace$, so
        by previous lemma between row index $j p^n$ and
        row index $(j+1)p^n -1$, there are $j$ maximal upside down triangles, therefore consider the sum:
        \begin{displaymath}
            \sum_{i=1}^{p-1}{i} = \frac{(p-1)p}{2}
        \end{displaymath}
        as required.

    \end{proof}

    \subsection{Using binomial symmetries}

    \begin{corollary}
    Let $\mathcal{P}$ be the Pascal array and let $p$ be a prime, than $k$-th column 
    is congruent to $k$-antidiagonal, modulo $p$.
    \end{corollary}
    \begin{proof}
        \begin{displaymath}
            \begin{split}
                { {n} \choose {k} } &\equiv_{p} { {n} \choose {n-k} } \\
                d_{nk} &\equiv_{p} d_{n,n-k}\\
                \sum_{n\geq 0}{d_{nk} t^n} &\equiv_{p}\sum_{n\geq 0}{d_{n,n-k} t^n} \\
                d(t)h(t)^k &\equiv_{p}\sum_{n\geq 0}{d_{n,n-k} t^n} \\
            \end{split}
        \end{displaymath}
    no a standard form for antidiagonal exists, so on the right we leave the explicit
    expression for the $k$-th antidiagonal.
    \end{proof}

    \begin{lemma}
        Let $p$ be a prime and take any $m, \gamma \in \mathbb{N}$. Let $n$ index
        over rows of a Pascal array $\mathcal{P}$, such that $p^{m} \leq n < p^{m+1}$, then the following holds:
        \begin{displaymath}
            d_{n,n-p^{m}} \equiv_{p} d_{n+\gamma p^{m+1}, n-p^{m}}
        \end{displaymath}
    \end{lemma}
    \begin{proof} % $n+\gamma p^{m+1}$
        By the basis representation theorem, write $n$  in base $p$ up to $k$ such that $k > m+1$ as necessary:
        \begin{displaymath}
            n = n_{0} + n_{1}p + n_{2}p^2 + \ldots + n_{m}p^m + 0p^{m+1} + \ldots + 0p^k
        \end{displaymath}
        Now consider the following quantities:
        \begin{displaymath}
            \begin{split}
                n +\gamma p^{m+1} &= n_{0} + n_{1}p + n_{2}p^2 + \ldots + n_{m}p^m + \gamma p^{m+1} + 0p^{m+2} \ldots + 0p^k \\
                n - p^{m} &= n_{0} + n_{1}p + n_{2}p^2 + \ldots + (n_{m}-1)p^m + 0p^{m+1} + \ldots + 0p^k \\
            \end{split}
        \end{displaymath}
        By Lucas theorem both the congruence:
        \begin{displaymath}
            {{n+\gamma p^{m+1}} \choose { n - p^{m}}} \equiv_{p} 
                {{n_{0}} \choose {n_{0}}}  
                {{n_{1}} \choose {n_{1}}} 
                {{n_{2}} \choose {n_{2}}}
                \ldots
                {{n_{m}} \choose {n_{m}-1}} 
                {{\gamma} \choose {0}} 
        \end{displaymath}
        both the following one:
        \begin{displaymath}
            {{n} \choose { n - p^{m}}} \equiv_{p} 
                {{n_{0}} \choose {n_{0}}}  
                {{n_{1}} \choose {n_{1}}} 
                {{n_{2}} \choose {n_{2}}}
                \ldots
                {{n_{m}} \choose {n_{m}-1}} 
        \end{displaymath}
        hold. Assuming ${{0}\choose{0}} = {{k}\choose{0}} = 1$ for any $k\in\mathbb{N}$, 
        transitivity property of $\equiv_p$ relation over right sides of
        the previous two congruences, it allows to derive congruence:
        \begin{displaymath}
            {{n} \choose { n - p^{m}}} \equiv_{p} {{n+\gamma p^{m+1}} \choose { n - p^{m}}} 
        \end{displaymath}
        which is the requested relation.
    \end{proof}

    Previous lemma is important because it does hold for the inverse array $\mathcal{P}^{-1}$ too:
    \begin{displaymath}
        \begin{split}
            \hat{d}_{n,n-p^{m}} &\equiv_{p} \hat{d}_{n+\gamma p^{m+1}, n-p^{m}} \\
            (-1)^{n-(n-p^{m})}d_{n,n-p^{m}} &\equiv_{p} (-1)^{n+\gamma p^{m+1}-(n-p^{m})}d_{n+\gamma p^{m+1}, n-p^{m}} \\
            (-1)^{p^{m}}d_{n,n-p^{m}} &\equiv_{p} (-1)^{p^{m}(\gamma p+1)}d_{n+\gamma p^{m+1}, n-p^{m}} \\
            (-1)^{p m}d_{n,n-p^{m}} &\equiv_{p} (-1)^{p{m}(\gamma p+1)}d_{n+\gamma p^{m+1}, n-p^{m}} \\
            (-1)^{p}d_{n,n-p^{m}} &\equiv_{p} (-1)^{p(\gamma p+1)}d_{n+\gamma p^{m+1}, n-p^{m}} \\
            (-1)^{p}d_{n,n-p^{m}} &\equiv_{p} (-1)^{p^2\gamma}(-1)^p d_{n+\gamma p^{m+1}, n-p^{m}} \\
            (-1)^{p}d_{n,n-p^{m}} &\equiv_{p} (-1)^{2p \gamma}(-1)^p d_{n+\gamma p^{m+1}, n-p^{m}} \\
            (-1)^{p}d_{n,n-p^{m}} &\equiv_{p} (-1)^p d_{n+\gamma p^{m+1}, n-p^{m}} \\
        \end{split}
    \end{displaymath}
    An even module $p$ produces exactly the same remainder classes both for $\mathcal{P}$ 
    both for $\mathcal{P}^{-1}$. Suppose $p$ odd, in this case $(-1)^{p} = -1$ and since there
    exists $(-1)^{-1}\mod p$:
    \begin{displaymath}
        \begin{split}
            d_{n,n-p^{m}} &\equiv_{p} d_{n+\gamma p^{m+1}, n-p^{m}} \\
        \end{split}
    \end{displaymath}
    which holds by the former lemma. Pay attention: this doesn't relate coefficients
    of $\mathcal{P}$ and $\mathcal{P}^{-1}$ (from the colouring point of view 
    doesn't imply any relation about colours assignment: generally it is not the case,
    except for even $p$), it merely says that 
    congruent coefficients on the chosen antidiagonal, \emph{in the same triangle
    either $\mathcal{P}$ or $\mathcal{P}^{-1}$}, repeat with structure.
    \\\\
    The following theorem tackle what the above argument leaves out: it 
    shows another characterization, we call it ``duality'', 
    over remainder classes for arrays $\mathcal{P}$ and its inverse, relating coefficients
    belonging to the two triangles.
    \begin{theorem}
        Let $d_{nk}, \hat{d}_{nk}$ be generic elements of arrays $\mathcal{P}$ and $\mathcal{P}^{-1}$,
        respectively. Choose an odd prime $p$, let $c\in \lbrace 0, \ldots, p-1 \rbrace$ a remainder class
        witness, then:
        \begin{displaymath}
            \begin{split}
                d_{n,n-p^{m}} \equiv_{p} c &\leftrightarrow \hat{d}_{n,n-p^{m}} \equiv_{p} p-c
            \end{split}
        \end{displaymath}
    \end{theorem}
    \begin{proof}
    We show both directions using a set of congruences: reading them from top to bottom provides a 
    proof for $\rightarrow$ direction, while reading them from bottom to top provides a proof for 
    $\leftarrow$ direction. Recall that $p^m$ is odd because $p$ is odd by hp, therefore $(-1)^{p^m} = -1$:
    \begin{displaymath}
        \begin{split}
            d_{n,n-p^{m}} &\equiv_{p} c \\
            (-1)^{p^m}\hat{d}_{n,n-p^{m}} &\equiv_{p} c \\
            (-1)^{p^m }(-1)\hat{d}_{n,n-p^{m}} &\equiv_{p} -c \\
            (-1)^{p^m }(-1)\hat{d}_{n,n-p^{m}} &\equiv_{p} p -c \\
            \hat{d}_{n,n-p^{m}} &\equiv_{p} p -c \\
        \end{split}
    \end{displaymath}
    \end{proof}


    \subsection{Expanded arrays and coloured triangles}

    % mod 2
    Expansion of Riordan array $\mathcal{P}$:
    \input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}
    Expansion of Riordan array $\mathcal{P}^{-1}$:
    \input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}

    \input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}

    % mod 3
    % the following matrices are identical to the previous ones
    %\input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-mod3-partitioning-include-matrix.tex}
    %\input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-mod3-partitioning-include-matrix.tex}

    \input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-mod3-partitioning-include-figure.tex}
    \input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-mod3-partitioning-include-figure.tex}

    % mod 5
    % the following matrices are identical to the previous ones
    %\input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-mod5-partitioning-include-matrix.tex}
    %\input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-mod5-partitioning-include-matrix.tex}

    \input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-mod5-partitioning-include-figure.tex}
    \input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-mod5-partitioning-include-figure.tex}

    % the following two rows refer to old triangles, pay attention on the filename schema.
    \input{../sympy/pascal/Pascal-standard-handle-negatives-plain-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/pascal/Pascal-inverse-handle-negatives-plain-colouring-127-rows-mod2-partitioning-include-figure.tex}

    \subsection{Coloured triangles: multiples of primes, abstracting over remainder classes}

    In this section we report some coloured triangles that use a partitioning similar to the modular one, 
    with the difference that, if $p$ is a module, than remainder classes $[1]_p, \ldots, [p-1]_p$
    are collected and abstracted as one big class, getting a single colour.

    Up to now, we ignore signs for inverse triangles, hence they are the same as the corresponding standard triangles.

    An observation: it is interesting to point out the colouring when a \emph{non prime} module $p$ is used, in
    our case $p=4$. The structure ``has noise'' respect structures relative to a prime $p$, where patterns
    show sharply.


    \input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-multiples-of-3-partitioning-include-figure}
    \input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-multiples-of-4-partitioning-include-figure}
    \input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-multiples-of-5-partitioning-include-figure}
    \input{../sympy/pascal/pascal-standard-ignore-negatives-centered-colouring-127-rows-multiples-of-7-partitioning-include-figure}

    % since we ignore signs, the inverses are the same of the standard ones.
    %\input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-multiples-of-3-partitioning-include-figure}
    %\input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-multiples-of-4-partitioning-include-figure}
    %\input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-multiples-of-5-partitioning-include-figure}
    %\input{../sympy/pascal/pascal-inverse-ignore-negatives-centered-colouring-127-rows-multiples-of-7-partitioning-include-figure}

    \section{Fibonacci}

    Expansion of Riordan array $\mathcal{F}$:
    \input{../sympy/fibonacci/Fibonacci-standard-handle-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}
    Expansion of Riordan array $\mathcal{F}^{-1}$:
    \input{../sympy/fibonacci/Fibonacci-inverse-handle-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}

    \input{../sympy/fibonacci/Fibonacci-standard-handle-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/fibonacci/Fibonacci-inverse-handle-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}

    \input{../sympy/fibonacci/Fibonacci-standard-handle-negatives-plain-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/fibonacci/Fibonacci-inverse-handle-negatives-plain-colouring-127-rows-mod2-partitioning-include-figure.tex}

    \section{Catalan}

    \subsection{Traditional version}

    Expansion of Riordan array $\mathcal{C}$:
    \input{../sympy/catalan/Catalan-traditional-standard-handle-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}
    Expansion of Riordan array $\mathcal{C}^{-1}$:
    \input{../sympy/catalan/Catalan-traditional-inverse-handle-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}

    \input{../sympy/catalan/Catalan-traditional-standard-handle-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/catalan/Catalan-traditional-inverse-handle-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}

    \subsection{Sprugnoli and He version}

    Expansion of Riordan array $\mathcal{C}$:
    \input{../sympy/catalan/catalan-sprugnoli-he-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}
    Expansion of Riordan array $\mathcal{C}^{-1}$:
    \input{../sympy/catalan/catalan-sprugnoli-he-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}

    \input{../sympy/catalan/catalan-sprugnoli-he-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/catalan/catalan-sprugnoli-he-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/catalan/Catalan-standard-handle-negatives-plain-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/catalan/Catalan-inverse-handle-negatives-plain-colouring-127-rows-mod2-partitioning-include-figure.tex}

    \subsection{Minor variants: triangles $\mathcal{S}, \mathcal{C}$ and $\mathcal{B}$}

    Expansion of Riordan array $\mathcal{S}$:
    \input{../sympy/catalan-like/catalan-variant-s-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{S}^{-1}$:
    \input{../sympy/catalan-like/catalan-variant-s-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{C}$:
    \input{../sympy/catalan-like/catalan-variant-c-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{C}^{-1}$:
    \input{../sympy/catalan-like/catalan-variant-c-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{B}$:
    \input{../sympy/catalan-like/catalan-variant-b-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{B}^{\diamond}$:
    \input{../sympy/catalan-like/catalan-variant-b-diamond-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}

    \input{../sympy/catalan-like/catalan-variant-s-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/catalan-like/catalan-variant-s-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/catalan-like/catalan-variant-c-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/catalan-like/catalan-variant-c-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/catalan-like/catalan-variant-b-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/catalan-like/catalan-variant-b-diamond-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}

    \section{Motzkin}

    \added[id=sid]{A possible recurrence should be the following, inspired by the 
    computation of the \emph{fractal dimensionality} of Pascal array:}
    \begin{displaymath}
        \added[id=sid]{\mathcal{M}(h+2) = 2\,\left(\mathcal{M}(h+1) + \mathcal{M}(h)\right)}
    \end{displaymath}
    \added[id=sid]{
    It is derived according the following reasoning. Let $\mathcal{M}_{h}$
    be the principal cluster of order $h$. Looking at the drawn triangle,
    we observe that cluster $\mathcal{M}_{h+2}$ is composed as follows:}
    \begin{itemize}
        \item \added[id=sid]{$\mathcal{M}_{h}$ repeats two times ``over the same columns'';}
        \item \added[id=sid]{$\mathcal{M}_{h+1}$ repeats two times: the first one covers the
            very top position, therefore from column $0$ to column $p^{h+1}-1$, included;
            the second one covers ``right-most columns'', 
            specifically covers from column $p^{h+1}$ to column $p^{h+2}-1$, included;}
        \item \added[id=sid]{two upside-down triangles (ie. pointing downward), of coefficients
            which prime $p$ divides, are introduced
            but they don't seem releated with the ones present in clusters 
            $\mathcal{M}_{h}$ and $\mathcal{M}_{h+1}$;}
        \item \added[id=sid]{another two triangles, with mixed coefficients, some of them
            are multiple of $p$, some aren't: however the two copies look similar.
            These two copies sit on the left of cluster $\mathcal{M}_{h+1}$ and
            are separated from it by a ``segment'' of coefficients (all even but
            the very first and the very last) lying on column $p^{h+1}-1$.}
    \end{itemize}
    \added[id=sid]{
    We need to be more precise about involved rows, nonetheless the very first
    antidiagonal plays a misleading role, since it is composed by $1$s only,
    and if we consider it, the previous points aren't ultimately correct,
    especially the repetitions of cluster $\mathcal{M}_{h}$.}

    Expansion of Riordan array $\mathcal{M}$:
    \input{../sympy/motzkin/motzkin-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{M}^{\diamond}$:
    \input{../sympy/motzkin/motzkin-diamond-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{T}$:
    \input{../sympy/motzkin/motzkin-variant-t-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{T}^{-1}$:
    \input{../sympy/motzkin/motzkin-variant-t-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{T}^{\perp}$:
    \input{../sympy/motzkin/motzkin-variant-t-perp-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}
    Expansion of Riordan array $\mathcal{T}^{\diamond}$:
    \input{../sympy/motzkin/motzkin-variant-t-diamond-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix}

    \input{../sympy/motzkin/motzkin-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/motzkin/motzkin-diamond-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/motzkin/motzkin-variant-t-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/motzkin/motzkin-variant-t-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/motzkin/motzkin-variant-t-perp-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    \input{../sympy/motzkin/motzkin-variant-t-diamond-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure}
    
    \input{../sympy/motzkin/Motzkin-standard-handle-negatives-plain-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/motzkin/Motzkin-inverse-handle-negatives-plain-colouring-127-rows-mod2-partitioning-include-figure.tex}

    \section{Delannoy}

    % mod 2
    Expansion of Riordan array $\mathcal{D}$:
    \input{../sympy/delannoy/delannoy-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}
    Expansion of Riordan array $\mathcal{D}^{-1}$:
    \input{../sympy/delannoy/delannoy-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-matrix.tex}

    \input{../sympy/delannoy/delannoy-standard-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}
    \input{../sympy/delannoy/delannoy-inverse-ignore-negatives-centered-colouring-127-rows-mod2-partitioning-include-figure.tex}

    % mod 3
    % the following matrices are identical to the previous ones
    %\input{../sympy/delannoy/delannoy-standard-ignore-negatives-centered-colouring-127-rows-mod3-partitioning-include-matrix.tex}
    %\input{../sympy/delannoy/delannoy-inverse-ignore-negatives-centered-colouring-127-rows-mod3-partitioning-include-matrix.tex}

    \input{../sympy/delannoy/delannoy-standard-handle-negatives-centered-colouring-127-rows-multiples-of-3-partitioning-include-figure}
    \input{../sympy/delannoy/delannoy-standard-handle-negatives-centered-colouring-127-rows-multiples-of-5-partitioning-include-figure}
    \input{../sympy/delannoy/delannoy-standard-handle-negatives-centered-colouring-127-rows-multiples-of-7-partitioning-include-figure}
    \input{../sympy/delannoy/delannoy-standard-handle-negatives-centered-colouring-127-rows-multiples-of-11-partitioning-include-figure}

    \input{../sympy/delannoy/delannoy-inverse-handle-negatives-centered-colouring-127-rows-multiples-of-3-partitioning-include-figure}
    \input{../sympy/delannoy/delannoy-inverse-handle-negatives-centered-colouring-127-rows-multiples-of-5-partitioning-include-figure}
    \input{../sympy/delannoy/delannoy-inverse-handle-negatives-centered-colouring-127-rows-multiples-of-7-partitioning-include-figure}
    \input{../sympy/delannoy/delannoy-inverse-handle-negatives-centered-colouring-127-rows-multiples-of-11-partitioning-include-figure}

    % bib stuff
    %\nocite{*}
    %\addtocontents{toc}{\protect\vspace{\beforebibskip}}
    %\addcontentsline{toc}{section}{\refname}    
    %\bibliographystyle{plain}
    %\bibliography{../Bibliography}
\end{document}
